{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly4xjbn6W_fN"
      },
      "source": [
        "Import all required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpJulPBiXC25"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import requests\n",
        "import base64\n",
        "import struct # For converting bytes to float\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiCIVzeDWhNk"
      },
      "source": [
        "This portion is for the Direct PyTorch/TensorFlow Integration.\n",
        "This should be finished around chunk 43."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXBdbONxRJ38",
        "outputId": "d8e59a36-b145-43d2-9fcf-ec4c1af74246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Initializing Layer Weights ---\n",
            "\n",
            "Initializing tensor of shape torch.Size([512, 512]) (262144 elements, 1048576 bytes needed).\n",
            "Starting fetch for 1048576 bytes in 64 chunk(s) (max 16384 bytes/chunk, 3 retries/chunk)...\n",
            "  Requesting chunk 1/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 1. Total fetched so far: 24576\n",
            "  Requesting chunk 2/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 2. Total fetched so far: 49152\n",
            "  Requesting chunk 3/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 3. Total fetched so far: 73728\n",
            "  Requesting chunk 4/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 4. Total fetched so far: 98304\n",
            "  Requesting chunk 5/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 5. Total fetched so far: 122880\n",
            "  Requesting chunk 6/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 6. Total fetched so far: 147456\n",
            "  Requesting chunk 7/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 7. Total fetched so far: 172032\n",
            "  Requesting chunk 8/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 8. Total fetched so far: 196608\n",
            "  Requesting chunk 9/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 9. Total fetched so far: 221184\n",
            "  Requesting chunk 10/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 10. Total fetched so far: 245760\n",
            "  Requesting chunk 11/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 11. Total fetched so far: 270336\n",
            "  Requesting chunk 12/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 12. Total fetched so far: 294912\n",
            "  Requesting chunk 13/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 13. Total fetched so far: 319488\n",
            "  Requesting chunk 14/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 14. Total fetched so far: 344064\n",
            "  Requesting chunk 15/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 15. Total fetched so far: 368640\n",
            "  Requesting chunk 16/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 16. Total fetched so far: 393216\n",
            "  Requesting chunk 17/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 17. Total fetched so far: 417792\n",
            "  Requesting chunk 18/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 18. Total fetched so far: 442368\n",
            "  Requesting chunk 19/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 19. Total fetched so far: 466944\n",
            "  Requesting chunk 20/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 20. Total fetched so far: 491520\n",
            "  Requesting chunk 21/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 21. Total fetched so far: 516096\n",
            "  Requesting chunk 22/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 22. Total fetched so far: 540672\n",
            "  Requesting chunk 23/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 23. Total fetched so far: 565248\n",
            "  Requesting chunk 24/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 24. Total fetched so far: 589824\n",
            "  Requesting chunk 25/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 25. Total fetched so far: 614400\n",
            "  Requesting chunk 26/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 26. Total fetched so far: 638976\n",
            "  Requesting chunk 27/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 27. Total fetched so far: 663552\n",
            "  Requesting chunk 28/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 28. Total fetched so far: 688128\n",
            "  Requesting chunk 29/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 29. Total fetched so far: 712704\n",
            "  Requesting chunk 30/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 30. Total fetched so far: 737280\n",
            "  Requesting chunk 31/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 31. Total fetched so far: 761856\n",
            "  Requesting chunk 32/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 32. Total fetched so far: 786432\n",
            "  Requesting chunk 33/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 33. Total fetched so far: 811008\n",
            "  Requesting chunk 34/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 34. Total fetched so far: 835584\n",
            "  Requesting chunk 35/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 35. Total fetched so far: 860160\n",
            "  Requesting chunk 36/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 36. Total fetched so far: 884736\n",
            "  Requesting chunk 37/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 37. Total fetched so far: 909312\n",
            "  Requesting chunk 38/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 38. Total fetched so far: 933888\n",
            "  Requesting chunk 39/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 39. Total fetched so far: 958464\n",
            "  Requesting chunk 40/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 40. Total fetched so far: 983040\n",
            "  Requesting chunk 41/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 41. Total fetched so far: 1007616\n",
            "  Requesting chunk 42/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 42. Total fetched so far: 1032192\n",
            "  Requesting chunk 43/64 (16384 bytes), attempt 1/4...\n",
            "  Received 24576 bytes for chunk 43. Total fetched so far: 1056768\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\n",
            "Successfully fetched 1056768 total bytes (needed 1048576).\n",
            "Tensor successfully initialized with quantum uniform U(-0.0442, 0.0442).\n",
            "\n",
            "--- Initializing Layer Bias ---\n",
            "\n",
            "Initializing tensor of shape torch.Size([512]) (512 elements, 2048 bytes needed).\n",
            "Starting fetch for 2048 bytes in 1 chunk(s) (max 16384 bytes/chunk, 3 retries/chunk)...\n",
            "  Requesting chunk 1/1 (2048 bytes), attempt 1/4...\n",
            "  Received 3072 bytes for chunk 1. Total fetched so far: 3072\n",
            "Successfully fetched 3072 total bytes (needed 2048).\n",
            "Tensor successfully initialized with quantum uniform U(-0.0442, 0.0442).\n",
            "\n",
            "Weight min/max after quantum init: -0.0351 / 0.0442 (Target range: [-0.0442, 0.0442])\n",
            "Bias min/max after quantum init: -0.0351 / 0.0438 (Target range: [-0.0442, 0.0442])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import requests\n",
        "import base64\n",
        "import struct\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "\n",
        "# --- Configuration ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    API_KEY = userdata.get('OCCYBYTE_API_KEY')\n",
        "    if not API_KEY:\n",
        "        print(\"Warning: OCCYBYTE_API_KEY secret found but is empty. Falling back to env var or placeholder.\")\n",
        "        API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
        "except ImportError:\n",
        "    print(\"Warning: google.colab not found. Using OCCYBYTE_API_KEY environment variable or placeholder.\")\n",
        "    API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
        "\n",
        "BASE_URL = \"https://entropy.occybyte.com/api/eris/invoke\"\n",
        "# *** Reduced Chunk Size ***\n",
        "MAX_BYTES_PER_REQUEST = 16 * 1024 # 16384 bytes\n",
        "FLOAT_PRECISION = torch.float32\n",
        "BYTES_PER_FLOAT = torch.finfo(FLOAT_PRECISION).bits // 8\n",
        "# Keep timeout moderate now that we have retries\n",
        "REQUEST_TIMEOUT = 15\n",
        "CHUNK_DELAY_SECONDS = 0.1\n",
        "# *** Added Retry Logic ***\n",
        "MAX_RETRIES = 3 # Number of retries per chunk\n",
        "RETRY_DELAY_SECONDS = 2 # Wait time between retries\n",
        "\n",
        "# --- Robust Quantum Byte Fetching with Chunking and Retries ---\n",
        "\n",
        "def fetch_quantum_bytes(total_bytes_needed: int, api_key: str) -> bytes | None:\n",
        "    \"\"\"\n",
        "    Fetches raw quantum bytes from the ERIS API, handling chunking and retries.\n",
        "    \"\"\"\n",
        "    if not api_key or api_key == \"YOUR_API_KEY_HERE\":\n",
        "        print(\"Error: API Key not configured.\")\n",
        "        return None\n",
        "\n",
        "    if total_bytes_needed <= 0:\n",
        "        return b''\n",
        "\n",
        "    all_fetched_bytes = bytearray()\n",
        "    bytes_remaining = total_bytes_needed # Track bytes still needed conceptually\n",
        "    # Calculate expected bytes based on actual need, not API chunk size\n",
        "    target_fetched_length = 0\n",
        "\n",
        "    # Calculate number of chunks based on the NEW max size\n",
        "    num_chunks = math.ceil(total_bytes_needed / MAX_BYTES_PER_REQUEST)\n",
        "\n",
        "    print(f\"Starting fetch for {total_bytes_needed} bytes in {num_chunks} chunk(s) (max {MAX_BYTES_PER_REQUEST} bytes/chunk, {MAX_RETRIES} retries/chunk)...\")\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        # Calculate how many bytes we *intend* to get in this chunk based on remaining need\n",
        "        bytes_to_request_this_chunk = min(total_bytes_needed - len(all_fetched_bytes), MAX_BYTES_PER_REQUEST)\n",
        "\n",
        "        if bytes_to_request_this_chunk <= 0:\n",
        "             print(\"Warning: Calculation resulted in 0 bytes requested for a chunk. This might indicate an issue.\")\n",
        "             continue # Skip if somehow we think we need 0 bytes for this chunk\n",
        "\n",
        "        url = f\"{BASE_URL}?size={bytes_to_request_this_chunk}\"\n",
        "        headers = {\"X-API-Key\": api_key}\n",
        "\n",
        "        # --- Retry Loop ---\n",
        "        success = False\n",
        "        for attempt in range(MAX_RETRIES + 1): # +1 for the initial try\n",
        "            try:\n",
        "                print(f\"  Requesting chunk {i+1}/{num_chunks} ({bytes_to_request_this_chunk} bytes), attempt {attempt+1}/{MAX_RETRIES+1}...\")\n",
        "                response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)\n",
        "                response.raise_for_status() # Check for HTTP errors (4xx, 5xx)\n",
        "\n",
        "                json_response = response.json()\n",
        "                if \"data\" in json_response:\n",
        "                    base64_data = json_response[\"data\"]\n",
        "                    chunk_bytes = base64.b64decode(base64_data)\n",
        "\n",
        "                    # We need *at least* bytes_to_request_this_chunk, but API might give more\n",
        "                    if len(chunk_bytes) < bytes_to_request_this_chunk:\n",
        "                         # Treat this as a failure for retry purposes\n",
        "                         raise ValueError(f\"API returned fewer bytes ({len(chunk_bytes)}) than requested ({bytes_to_request_this_chunk})\")\n",
        "\n",
        "                    all_fetched_bytes.extend(chunk_bytes)\n",
        "                    print(f\"  Received {len(chunk_bytes)} bytes for chunk {i+1}. Total fetched so far: {len(all_fetched_bytes)}\")\n",
        "                    success = True # Mark success for this chunk\n",
        "                    break # Exit retry loop on success\n",
        "\n",
        "                else:\n",
        "                    # Treat missing 'data' field as a failure for retry\n",
        "                    raise ValueError(\"'data' field not found in API response\")\n",
        "\n",
        "            except requests.exceptions.Timeout:\n",
        "                 print(f\"  Attempt {attempt+1} timed out after {REQUEST_TIMEOUT} seconds.\")\n",
        "                 # Continue to next retry attempt if not the last one\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"  Attempt {attempt+1} failed with network/HTTP error: {e}\")\n",
        "                # Can check e.response.status_code here for specific handling if needed\n",
        "                # Continue to next retry attempt if not the last one\n",
        "            except (ValueError, TypeError, base64.binascii.Error) as e:\n",
        "                 print(f\"  Attempt {attempt+1} failed during data processing: {e}\")\n",
        "                 # These are less likely to be transient, but retry anyway\n",
        "            except Exception as e: # Catch any other unexpected errors\n",
        "                 print(f\"  Attempt {attempt+1} failed with unexpected error: {e}\")\n",
        "\n",
        "            # If not the last attempt and not successful, wait before retrying\n",
        "            if not success and attempt < MAX_RETRIES:\n",
        "                print(f\"  Waiting {RETRY_DELAY_SECONDS}s before retrying...\")\n",
        "                time.sleep(RETRY_DELAY_SECONDS)\n",
        "            elif not success and attempt == MAX_RETRIES:\n",
        "                 print(f\"Chunk {i+1} failed after {MAX_RETRIES+1} attempts. Aborting fetch.\")\n",
        "                 return None # Failed to get this chunk after all retries\n",
        "\n",
        "        # --- End Retry Loop ---\n",
        "\n",
        "        # Add a small delay before the next chunk request if successful\n",
        "        if success and i < num_chunks - 1:\n",
        "             time.sleep(CHUNK_DELAY_SECONDS)\n",
        "\n",
        "    # Final check: Ensure we have accumulated AT LEAST the total bytes needed\n",
        "    # This check is crucial because the API might return more bytes per chunk\n",
        "    if len(all_fetched_bytes) < total_bytes_needed:\n",
        "        print(f\"Error: Fetching completed, but total bytes received ({len(all_fetched_bytes)}) is less than required ({total_bytes_needed}).\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Successfully fetched {len(all_fetched_bytes)} total bytes (needed {total_bytes_needed}).\")\n",
        "    return bytes(all_fetched_bytes)\n",
        "\n",
        "\n",
        "# --- Quantum Weight Initialization Function (Unchanged from previous version) ---\n",
        "\n",
        "def quantum_uniform_init_(tensor: torch.Tensor, api_key: str, a: float = 0.0, b: float = 1.0):\n",
        "    \"\"\"\n",
        "    Initializes the input tensor with quantum random numbers following a uniform\n",
        "    distribution U(a, b). Modifies the tensor in-place. Uses chunking/retries.\n",
        "    \"\"\"\n",
        "    if not isinstance(tensor, torch.Tensor):\n",
        "        raise TypeError(\"Input must be a PyTorch Tensor\")\n",
        "    if a >= b:\n",
        "         raise ValueError(\"Lower bound 'a' must be less than upper bound 'b'\")\n",
        "\n",
        "    num_elements = tensor.numel()\n",
        "    if num_elements == 0:\n",
        "         print(\"Tensor has no elements. Skipping initialization.\")\n",
        "         return\n",
        "\n",
        "    bytes_needed = num_elements * BYTES_PER_FLOAT\n",
        "\n",
        "    print(f\"\\nInitializing tensor of shape {tensor.shape} ({num_elements} elements, {bytes_needed} bytes needed).\")\n",
        "    all_quantum_bytes = fetch_quantum_bytes(bytes_needed, api_key) # Calls the updated fetcher\n",
        "\n",
        "    if all_quantum_bytes is None:\n",
        "        print(\"Failed to fetch sufficient quantum bytes for initialization. Tensor not modified.\")\n",
        "        return\n",
        "\n",
        "    exact_quantum_bytes = all_quantum_bytes[:bytes_needed]\n",
        "\n",
        "    if len(exact_quantum_bytes) != bytes_needed:\n",
        "         print(f\"Error: After slicing, byte count ({len(exact_quantum_bytes)}) does not match required ({bytes_needed}).\")\n",
        "         return\n",
        "\n",
        "    if BYTES_PER_FLOAT != 4:\n",
        "         raise NotImplementedError(\"Only float32 initialization (4 bytes) is currently implemented with struct.\")\n",
        "\n",
        "    try:\n",
        "        uint_iterator = struct.iter_unpack('<I', exact_quantum_bytes)\n",
        "        max_uint32 = (1 << 32) - 1\n",
        "        quantum_floats_0_1 = torch.tensor(\n",
        "            [float(val) / (max_uint32 + 1) for val, in uint_iterator],\n",
        "            dtype=FLOAT_PRECISION\n",
        "        )\n",
        "\n",
        "        if quantum_floats_0_1.numel() != num_elements:\n",
        "             print(f\"Error: Number of generated floats ({quantum_floats_0_1.numel()}) does not match tensor elements ({num_elements}) after unpacking.\")\n",
        "             return\n",
        "\n",
        "        quantum_uniform_values = a + (b - a) * quantum_floats_0_1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            tensor.copy_(quantum_uniform_values.reshape(tensor.shape))\n",
        "\n",
        "        print(f\"Tensor successfully initialized with quantum uniform U({a:.4f}, {b:.4f}).\")\n",
        "\n",
        "    except struct.error as e:\n",
        "        print(f\"Error unpacking bytes into floats: {e}. Tensor not modified.\")\n",
        "    except Exception as e:\n",
        "         print(f\"An unexpected error occurred during float conversion or assignment: {e}. Tensor not modified.\")\n",
        "\n",
        "\n",
        "# --- Example Usage (Unchanged) ---\n",
        "\n",
        "# Define the layer\n",
        "layer_in_features = 512\n",
        "layer_out_features = 512\n",
        "linear_layer = torch.nn.Linear(layer_in_features, layer_out_features, bias=True)\n",
        "\n",
        "# Calculate default PyTorch uniform bounds\n",
        "k = 1.0 / layer_in_features\n",
        "bound = math.sqrt(k)\n",
        "weight_a, weight_b = -bound, bound\n",
        "bias_a, bias_b = -bound, bound # Default bias bounds are same\n",
        "\n",
        "# Initialize weights\n",
        "print(\"\\n--- Initializing Layer Weights ---\")\n",
        "quantum_uniform_init_(linear_layer.weight.data, API_KEY, a=weight_a, b=weight_b)\n",
        "\n",
        "# Initialize bias\n",
        "if linear_layer.bias is not None:\n",
        "    print(\"\\n--- Initializing Layer Bias ---\")\n",
        "    quantum_uniform_init_(linear_layer.bias.data, API_KEY, a=bias_a, b=bias_b)\n",
        "\n",
        "# Verify (optional)\n",
        "if linear_layer.weight.numel() > 0:\n",
        "     default_weight = torch.nn.Linear(layer_in_features, layer_out_features, bias=False).weight.data\n",
        "     if torch.equal(linear_layer.weight.data, default_weight):\n",
        "          print(\"\\nWarning: Weights seem unchanged from default initialization (Quantum fetch likely failed).\")\n",
        "     else:\n",
        "          print(f\"\\nWeight min/max after quantum init: {linear_layer.weight.min().item():.4f} / {linear_layer.weight.max().item():.4f} (Target range: [{weight_a:.4f}, {weight_b:.4f}])\")\n",
        "\n",
        "if linear_layer.bias is not None and linear_layer.bias.numel() > 0:\n",
        "     default_bias = torch.nn.Linear(layer_in_features, layer_out_features, bias=True).bias.data\n",
        "     if torch.equal(linear_layer.bias.data, default_bias):\n",
        "           print(\"Warning: Bias seems unchanged from default initialization (Quantum fetch likely failed).\")\n",
        "     else:\n",
        "          print(f\"Bias min/max after quantum init: {linear_layer.bias.min().item():.4f} / {linear_layer.bias.max().item():.4f} (Target range: [{bias_a:.4f}, {bias_b:.4f}])\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If9TO03BWq_i"
      },
      "source": [
        "This next part is for text generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyZngQZJRWPD",
        "outputId": "ac65a985-3a2a-4f61-cd1e-0627ea1d3819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: gpt2...\n",
            "Model and tokenizer loaded.\n",
            "Input token IDs: [[50256]]\n",
            "Running model inference...\n",
            "Logits shape for next token: torch.Size([50257])\n",
            "Sampling next token using quantum randomness (fetching 8 bytes)...\n",
            "Starting fetch for 8 bytes in 1 chunk(s) (max 16384 bytes/chunk, 3 retries/chunk)...\n",
            "  Requesting chunk 1/1 (8 bytes)...\n",
            "  Received 12 bytes.\n",
            "Quantum-selected token ID: 198\n",
            "Quantum-selected token: '\n",
            "'\n"
          ]
        }
      ],
      "source": [
        "# --- LLM Text Generation Sampling Example ---\n",
        "\n",
        "import requests\n",
        "import torch\n",
        "import transformers\n",
        "import os\n",
        "import base64\n",
        "import struct # For converting bytes to float\n",
        "import time # For potential delays\n",
        "import math # For ceiling calculation\n",
        "\n",
        "# --- Configuration (Needs to be defined before helpers) ---\n",
        "try:\n",
        "    # Use Colab secrets if available\n",
        "    from google.colab import userdata\n",
        "    API_KEY = userdata.get('OCCYBYTE_API_KEY')\n",
        "    if not API_KEY:\n",
        "        print(\"Warning: OCCYBYTE_API_KEY secret found but is empty. Falling back to env var or placeholder.\")\n",
        "        API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
        "except ImportError:\n",
        "    # Fallback for environments without google.colab\n",
        "    print(\"Warning: google.colab not found. Using OCCYBYTE_API_KEY environment variable or placeholder.\")\n",
        "    API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
        "\n",
        "BASE_URL = \"https://entropy.occybyte.com/api/eris/invoke\"\n",
        "# Use the same robust settings as weight init for consistency,\n",
        "# even though we only need a few bytes here.\n",
        "MAX_BYTES_PER_REQUEST = 16 * 1024 # 16384 bytes\n",
        "REQUEST_TIMEOUT = 15\n",
        "CHUNK_DELAY_SECONDS = 0.1\n",
        "MAX_RETRIES = 3\n",
        "RETRY_DELAY_SECONDS = 2\n",
        "\n",
        "NUM_BYTES_FOR_FLOAT_SAMPLING = 8 # Use 8 bytes (64 bits) for higher precision random float\n",
        "\n",
        "# --- Robust Quantum Byte Fetching (Required by fetch_quantum_float) ---\n",
        "# (Include the full fetch_quantum_bytes function from the weight init example here)\n",
        "def fetch_quantum_bytes(total_bytes_needed: int, api_key: str) -> bytes | None:\n",
        "    \"\"\"\n",
        "    Fetches raw quantum bytes from the ERIS API, handling chunking and retries.\n",
        "    (Same implementation as in the weight initialization example)\n",
        "    \"\"\"\n",
        "    if not api_key or api_key == \"YOUR_API_KEY_HERE\":\n",
        "        print(\"Error: API Key not configured.\")\n",
        "        return None\n",
        "\n",
        "    if total_bytes_needed <= 0:\n",
        "        return b''\n",
        "\n",
        "    all_fetched_bytes = bytearray()\n",
        "    # Calculate number of chunks based on the NEW max size\n",
        "    num_chunks = math.ceil(total_bytes_needed / MAX_BYTES_PER_REQUEST)\n",
        "\n",
        "    print(f\"Starting fetch for {total_bytes_needed} bytes in {num_chunks} chunk(s) (max {MAX_BYTES_PER_REQUEST} bytes/chunk, {MAX_RETRIES} retries/chunk)...\")\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        bytes_to_request_this_chunk = min(total_bytes_needed - len(all_fetched_bytes), MAX_BYTES_PER_REQUEST)\n",
        "        if bytes_to_request_this_chunk <= 0: break # Already fetched enough\n",
        "\n",
        "        url = f\"{BASE_URL}?size={bytes_to_request_this_chunk}\"\n",
        "        headers = {\"X-API-Key\": api_key}\n",
        "\n",
        "        success = False\n",
        "        for attempt in range(MAX_RETRIES + 1):\n",
        "            try:\n",
        "                # Reduced print frequency for float fetching as it's small\n",
        "                if attempt == 0:\n",
        "                    print(f\"  Requesting chunk {i+1}/{num_chunks} ({bytes_to_request_this_chunk} bytes)...\")\n",
        "                else:\n",
        "                     print(f\"  Retrying chunk {i+1}, attempt {attempt+1}...\")\n",
        "\n",
        "                response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                json_response = response.json()\n",
        "                if \"data\" in json_response:\n",
        "                    base64_data = json_response[\"data\"]\n",
        "                    chunk_bytes = base64.b64decode(base64_data)\n",
        "                    if len(chunk_bytes) < bytes_to_request_this_chunk:\n",
        "                         raise ValueError(f\"API returned fewer bytes ({len(chunk_bytes)}) than requested ({bytes_to_request_this_chunk})\")\n",
        "\n",
        "                    all_fetched_bytes.extend(chunk_bytes)\n",
        "                    if attempt == 0: # Only print success on first try\n",
        "                         print(f\"  Received {len(chunk_bytes)} bytes.\")\n",
        "                    success = True\n",
        "                    break\n",
        "                else:\n",
        "                    raise ValueError(\"'data' field not found in API response\")\n",
        "            except Exception as e: # Catch all errors for retry logic\n",
        "                print(f\"  Attempt {attempt+1} failed: {e}\")\n",
        "                if attempt < MAX_RETRIES:\n",
        "                    print(f\"  Waiting {RETRY_DELAY_SECONDS}s before retrying...\")\n",
        "                    time.sleep(RETRY_DELAY_SECONDS)\n",
        "                else:\n",
        "                     print(f\"Chunk {i+1} failed after {MAX_RETRIES+1} attempts. Aborting fetch.\")\n",
        "                     return None\n",
        "\n",
        "        if not success: return None # Exit if a chunk failed permanently\n",
        "        if success and i < num_chunks - 1: time.sleep(CHUNK_DELAY_SECONDS)\n",
        "\n",
        "    if len(all_fetched_bytes) < total_bytes_needed:\n",
        "        print(f\"Error: Final fetched bytes ({len(all_fetched_bytes)}) less than required ({total_bytes_needed}).\")\n",
        "        return None\n",
        "\n",
        "    # No need to print total for small float requests\n",
        "    # print(f\"Successfully fetched {len(all_fetched_bytes)} total bytes (needed {total_bytes_needed}).\")\n",
        "    return bytes(all_fetched_bytes)\n",
        "\n",
        "\n",
        "# --- Helper Function: Fetch Quantum Float ---\n",
        "\n",
        "def fetch_quantum_float(num_bytes: int, api_key: str) -> float | None:\n",
        "    \"\"\"\n",
        "    Fetches quantum bytes using the robust fetcher and converts them\n",
        "    into a float in the range [0.0, 1.0).\n",
        "    \"\"\"\n",
        "    quantum_bytes = fetch_quantum_bytes(num_bytes, api_key) # Use the robust fetcher\n",
        "\n",
        "    if quantum_bytes is None:\n",
        "        return None # Error handled in fetch_quantum_bytes\n",
        "\n",
        "    # Slice to exact size needed, in case fetcher returned more (less likely for small requests)\n",
        "    exact_quantum_bytes = quantum_bytes[:num_bytes]\n",
        "    if len(exact_quantum_bytes) != num_bytes:\n",
        "         print(f\"Error: Sliced byte count ({len(exact_quantum_bytes)}) mismatch after fetch ({num_bytes} needed).\")\n",
        "         return None\n",
        "\n",
        "    try:\n",
        "        if num_bytes == 8:\n",
        "            random_int = struct.unpack('<Q', exact_quantum_bytes)[0] # <Q = little-endian unsigned 64-bit int\n",
        "            max_val = (1 << 64) - 1\n",
        "        elif num_bytes == 4:\n",
        "             random_int = struct.unpack('<I', exact_quantum_bytes)[0] # <I = little-endian unsigned 32-bit int\n",
        "             max_val = (1 << 32) - 1\n",
        "        else:\n",
        "             # Fallback for other sizes (less ideal distribution)\n",
        "             random_int = int.from_bytes(exact_quantum_bytes, byteorder='little', signed=False)\n",
        "             max_val = (1 << (num_bytes * 8)) - 1\n",
        "\n",
        "        # Normalize to [0.0, 1.0)\n",
        "        return float(random_int) / (max_val + 1)\n",
        "\n",
        "    except struct.error as e:\n",
        "         print(f\"Error unpacking bytes for float: {e}\")\n",
        "         return None\n",
        "    except Exception as e:\n",
        "         print(f\"Unexpected error converting bytes to float: {e}\")\n",
        "         return None\n",
        "\n",
        "\n",
        "# --- Quantum Sampling Function ---\n",
        "\n",
        "def quantum_enhanced_sampling(logits: torch.Tensor, api_key: str, temperature: float = 1.0) -> int | None:\n",
        "    \"\"\"\n",
        "    Samples a token index from logits using quantum randomness via inverse transform sampling.\n",
        "    \"\"\"\n",
        "    if temperature <= 0:\n",
        "        print(\"Warning: Temperature should be positive. Using temperature=1.0\")\n",
        "        temperature = 1.0\n",
        "\n",
        "    # Fetch a single high-precision quantum random float [0.0, 1.0)\n",
        "    quantum_rand_float = fetch_quantum_float(NUM_BYTES_FOR_FLOAT_SAMPLING, api_key)\n",
        "\n",
        "    if quantum_rand_float is None:\n",
        "        print(\"Failed to get quantum random number for sampling.\")\n",
        "        return None\n",
        "\n",
        "    probabilities = torch.nn.functional.softmax(logits / temperature, dim=-1)\n",
        "    cumulative_probs = torch.cumsum(probabilities, dim=-1)\n",
        "\n",
        "    # Add a small epsilon to handle potential float issues at boundaries\n",
        "    epsilon = 1e-9\n",
        "    sampled_index = torch.searchsorted(cumulative_probs,\n",
        "                                      torch.tensor([quantum_rand_float + epsilon], device=logits.device),\n",
        "                                      right=False)\n",
        "\n",
        "    return sampled_index.item()\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "try:\n",
        "    # Ensure transformers is installed: pip install transformers\n",
        "    import transformers\n",
        "\n",
        "    model_name = \"gpt2\"\n",
        "    print(f\"Loading model: {model_name}...\")\n",
        "    model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    print(\"Model and tokenizer loaded.\")\n",
        "\n",
        "    if tokenizer.bos_token_id is not None:\n",
        "        input_ids = torch.tensor([[tokenizer.bos_token_id]])\n",
        "    else:\n",
        "         input_text = \"The\"\n",
        "         print(f\"Warning: BOS token not found for {model_name}. Starting sequence with '{input_text}'.\")\n",
        "         input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    print(f\"Input token IDs: {input_ids.tolist()}\")\n",
        "\n",
        "    print(\"Running model inference...\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        next_token_logits = outputs.logits[0, -1, :]\n",
        "    print(f\"Logits shape for next token: {next_token_logits.shape}\")\n",
        "\n",
        "    print(f\"Sampling next token using quantum randomness (fetching {NUM_BYTES_FOR_FLOAT_SAMPLING} bytes)...\")\n",
        "    selected_token_id = quantum_enhanced_sampling(next_token_logits, API_KEY, temperature=0.8)\n",
        "\n",
        "    if selected_token_id is not None:\n",
        "        selected_token = tokenizer.decode([selected_token_id])\n",
        "        print(f\"Quantum-selected token ID: {selected_token_id}\")\n",
        "        print(f\"Quantum-selected token: '{selected_token}'\")\n",
        "    else:\n",
        "        print(\"Failed to sample token due to an error.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Error: Please install PyTorch and Transformers (`pip install torch transformers`)\")\n",
        "except Exception as e:\n",
        "     print(f\"An unexpected error occurred during model loading or inference: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HwoR2btRYpu"
      },
      "source": [
        "This is the AI Sampling example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeEuov_oRYzq",
        "outputId": "a733ce2f-69b9-45dd-b3c4-8dd7882c3a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Attempting to select 15 items using quantum randomness...\n",
            "Workaround: Adjusted request size from 15 to 24 to potentially avoid API padding errors.\n",
            "Starting fetch for 15 bytes (requesting 24) in 1 chunk(s)...\n",
            "  Requesting chunk 1/1 (24 bytes), attempt 1/4...\n",
            "  Received 24 bytes. Total fetched so far: 24\n",
            "Successfully fetched 24 total bytes (originally needed 15).\n",
            "Quantum-selected items (15): ['sample', 'a', 'quantum', 'quantum', 'sample', 'entropy', 'quantum', 'sample', 'sample', 'entropy', 'one', 'one', 'one', 'quantum', 'some']\n"
          ]
        }
      ],
      "source": [
        "# --- Quantum Choice Sampling Example ---\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import base64\n",
        "import math # For ceiling calculation\n",
        "import time # For delays\n",
        "\n",
        "# --- Configuration ---\n",
        "try:\n",
        "    # Use Colab secrets if available\n",
        "    from google.colab import userdata\n",
        "    API_KEY = userdata.get('OCCYBYTE_API_KEY')\n",
        "    if not API_KEY:\n",
        "        print(\"Warning: OCCYBYTE_API_KEY secret found but is empty. Falling back to env var or placeholder.\")\n",
        "        API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
        "except ImportError:\n",
        "    # Fallback for environments without google.colab\n",
        "    print(\"Warning: google.colab not found. Using OCCYBYTE_API_KEY environment variable or placeholder.\")\n",
        "    API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
        "\n",
        "BASE_URL = \"https://entropy.occybyte.com/api/eris/invoke\"\n",
        "# Use the same robust settings, even for potentially smaller requests\n",
        "MAX_BYTES_PER_REQUEST = 16 * 1024 # 16384 bytes\n",
        "REQUEST_TIMEOUT = 15\n",
        "CHUNK_DELAY_SECONDS = 0.1\n",
        "MAX_RETRIES = 3\n",
        "RETRY_DELAY_SECONDS = 2\n",
        "\n",
        "# --- Robust Quantum Byte Fetching (with Chunking, Retries, and Small Request Workaround) ---\n",
        "def fetch_quantum_bytes(total_bytes_needed: int, api_key: str) -> bytes | None:\n",
        "    \"\"\"\n",
        "    Fetches raw quantum bytes from the ERIS API, handling chunking, retries,\n",
        "    and adding a workaround for potential API base64 padding errors on small requests.\n",
        "    \"\"\"\n",
        "    if not api_key or api_key == \"YOUR_API_KEY_HERE\":\n",
        "        print(\"Error: API Key not configured.\")\n",
        "        return None\n",
        "\n",
        "    if total_bytes_needed <= 0:\n",
        "        return b''\n",
        "\n",
        "    # --- Workaround: Define a minimum request size known to work ---\n",
        "    # We saw it return 24 bytes for 16, and 12 bytes for 8. Let's try 16 or 24 as a minimum.\n",
        "    # Using 24 seems safer as it's a multiple of 3 (good for base64) and we saw it returned.\n",
        "    MIN_REQUEST_SIZE_WORKAROUND = 24\n",
        "    bytes_to_actually_request = max(total_bytes_needed, MIN_REQUEST_SIZE_WORKAROUND) \\\n",
        "                                    if total_bytes_needed < MAX_BYTES_PER_REQUEST else total_bytes_needed\n",
        "    # Only apply workaround if the total needed is small AND fits within one chunk.\n",
        "    # If total_bytes_needed is large, chunking takes over anyway.\n",
        "\n",
        "    if bytes_to_actually_request > total_bytes_needed:\n",
        "         print(f\"Workaround: Adjusted request size from {total_bytes_needed} to {bytes_to_actually_request} to potentially avoid API padding errors.\")\n",
        "\n",
        "    all_fetched_bytes = bytearray()\n",
        "    # Calculate chunks based on the potentially adjusted request size\n",
        "    num_chunks = math.ceil(bytes_to_actually_request / MAX_BYTES_PER_REQUEST)\n",
        "\n",
        "    print(f\"Starting fetch for {total_bytes_needed} bytes (requesting {bytes_to_actually_request}) in {num_chunks} chunk(s)...\")\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        # Calculate based on bytes_to_actually_request\n",
        "        bytes_to_request_this_chunk = min(bytes_to_actually_request - len(all_fetched_bytes), MAX_BYTES_PER_REQUEST)\n",
        "        if bytes_to_request_this_chunk <= 0: break\n",
        "\n",
        "        url = f\"{BASE_URL}?size={bytes_to_request_this_chunk}\"\n",
        "        headers = {\"X-API-Key\": api_key}\n",
        "\n",
        "        success = False\n",
        "        for attempt in range(MAX_RETRIES + 1):\n",
        "            try:\n",
        "                print(f\"  Requesting chunk {i+1}/{num_chunks} ({bytes_to_request_this_chunk} bytes), attempt {attempt+1}/{MAX_RETRIES+1}...\")\n",
        "                response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                json_response = response.json()\n",
        "                if \"data\" in json_response:\n",
        "                    base64_data = json_response[\"data\"]\n",
        "                    # >>> Try decoding here to catch padding error early <<<\n",
        "                    try:\n",
        "                         chunk_bytes = base64.b64decode(base64_data)\n",
        "                    except base64.binascii.Error as decode_error:\n",
        "                         # Re-raise as a ValueError to be caught by the retry loop's general exception handler\n",
        "                         raise ValueError(f\"Base64 decode failed: {decode_error}. API likely returned malformed data for size {bytes_to_request_this_chunk}.\")\n",
        "\n",
        "                    # Check if API returned *at least* what we asked for (it might return more)\n",
        "                    # This check might be less critical now if the decode succeeded, but keep for safety\n",
        "                    if len(chunk_bytes) < bytes_to_request_this_chunk:\n",
        "                         raise ValueError(f\"API returned fewer bytes ({len(chunk_bytes)}) than requested ({bytes_to_request_this_chunk}) after successful decode.\")\n",
        "\n",
        "                    all_fetched_bytes.extend(chunk_bytes)\n",
        "                    print(f\"  Received {len(chunk_bytes)} bytes. Total fetched so far: {len(all_fetched_bytes)}\")\n",
        "                    success = True\n",
        "                    break # Exit retry loop on success\n",
        "                else:\n",
        "                    raise ValueError(\"'data' field not found in API response\")\n",
        "            except Exception as e: # Catches network errors, status errors, ValueErrors from above\n",
        "                print(f\"  Attempt {attempt+1} failed: {e}\")\n",
        "                if attempt < MAX_RETRIES:\n",
        "                    print(f\"  Waiting {RETRY_DELAY_SECONDS}s before retrying...\")\n",
        "                    time.sleep(RETRY_DELAY_SECONDS)\n",
        "                else:\n",
        "                     print(f\"Chunk {i+1} failed after {MAX_RETRIES+1} attempts. Aborting fetch.\")\n",
        "                     return None # Failed to get this chunk after all retries\n",
        "\n",
        "        if not success: return None # Exit loop if a chunk failed permanently\n",
        "        if success and i < num_chunks - 1: time.sleep(CHUNK_DELAY_SECONDS)\n",
        "\n",
        "    # --- Check final byte count against ORIGINAL needed amount ---\n",
        "    if len(all_fetched_bytes) < total_bytes_needed:\n",
        "        print(f\"Error: Final fetched bytes ({len(all_fetched_bytes)}) less than originally required ({total_bytes_needed}).\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Successfully fetched {len(all_fetched_bytes)} total bytes (originally needed {total_bytes_needed}).\")\n",
        "    # Return the fetched bytes (potentially more than originally needed, will be sliced later)\n",
        "    return bytes(all_fetched_bytes)\n",
        "\n",
        "\n",
        "# --- Quantum Choice Sampling Function ---\n",
        "def quantum_choice_sampler(options: list, num_samples: int, api_key: str) -> list | None:\n",
        "    \"\"\"\n",
        "    Selects items from a list using quantum random bytes fetched via API.\n",
        "    Note: Uses simple modulo mapping, which may introduce slight bias\n",
        "          if len(options) does not evenly divide 256.\n",
        "\n",
        "    Args:\n",
        "        options: The list of items to choose from.\n",
        "        num_samples: The number of samples to generate (fetches this many bytes).\n",
        "        api_key: Your Occybyte API key.\n",
        "\n",
        "    Returns:\n",
        "        A list containing num_samples items selected from options,\n",
        "        or None if an error occurred during fetching.\n",
        "    \"\"\"\n",
        "    if not options:\n",
        "        print(\"Error: Options list cannot be empty.\")\n",
        "        return None\n",
        "    if num_samples <= 0:\n",
        "        print(\"Error: Number of samples must be positive.\")\n",
        "        return None\n",
        "\n",
        "    # Fetch exactly num_samples bytes using the robust fetcher\n",
        "    all_quantum_bytes = fetch_quantum_bytes(num_samples, api_key)\n",
        "\n",
        "    if all_quantum_bytes is None:\n",
        "        print(\"Failed to fetch quantum bytes for sampling.\")\n",
        "        return None # Error message handled in fetch_quantum_bytes\n",
        "\n",
        "    # --- Slice the received bytes to EXACTLY the amount needed ---\n",
        "    # Handles cases where the API returned more bytes than requested.\n",
        "    exact_quantum_bytes = all_quantum_bytes[:num_samples]\n",
        "\n",
        "    if len(exact_quantum_bytes) != num_samples:\n",
        "        print(f\"Error: After slicing, byte count ({len(exact_quantum_bytes)}) doesn't match required ({num_samples}).\")\n",
        "        return Nonea\n",
        "\n",
        "    num_options = len(options)\n",
        "    # Use list comprehension for a functional style with the correctly sized byte list\n",
        "    selected_indices = [byte % num_options for byte in exact_quantum_bytes]\n",
        "\n",
        "    return [options[i] for i in selected_indices]\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "potential_next_tokens = [\"the\", \"a\", \"one\", \"this\", \"some\", \"quantum\", \"random\", \"choice\", \"entropy\", \"sample\"]\n",
        "num_choices = 15 # How many tokens we want to select\n",
        "\n",
        "print(f\"\\nAttempting to select {num_choices} items using quantum randomness...\")\n",
        "selected_tokens = quantum_choice_sampler(potential_next_tokens, num_choices, API_KEY)\n",
        "\n",
        "if selected_tokens:\n",
        "    print(f\"Quantum-selected items ({len(selected_tokens)}): {selected_tokens}\")\n",
        "else:\n",
        "    print(\"Failed to select items due to an error during data fetch.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1uVaQ9KiXKl"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642,
          "referenced_widgets": [
            "ba702c72d3644ca992060c0ac4ab789b",
            "66707e797f8344bfa910755d521afa0c",
            "f33c59a1a2f841eebae801bbbf306cd9",
            "ebf192f26c244593a8eb660dcc66b299",
            "3df7d4e189c84ad785fe643f059939fc",
            "4d179bfbd7f048cb9ed752911aeb1a93",
            "00104ad662484e6ca6de32af8133e18b",
            "62f87ea27ed84a99b61ffebf32b01ad4",
            "23917413a3bb4427b5ef7a6379f2f59a",
            "2372ff956f2c47e4a67fd80d5235919d",
            "994be6fb7e3c4e86ab5d97044ccd488b",
            "fd083ec6ebf6414b96e6f06ed215e60e",
            "85d79d598e7e429498780cf2a6a37220",
            "26061f499a414f1e90567abd1bd0c673",
            "704bdf70c444482fb4df26cdf4e688a4",
            "9a1845f6ff94429783dfe1e06e335faf",
            "37e6d7ab044c4cb1aebaf5b111f44fd0",
            "5136e93c483d46a8a8373e66d63e69d2",
            "aadb4671c41f4f548631fabd9865d497",
            "b80dc258728643f8acfcb77240438893",
            "4fba1ad00d1d4698aff81e6d4e05cd94",
            "549de8a3c50644bd9f5bb9924f75faf0",
            "53c9bb728c87411a84deceebf06195ce",
            "6244d317560b48ea946cb768921aa795",
            "8769c660ac4446e5b51947b21c9b220c",
            "ddbb86469de04a6aac0df809e8ae4876",
            "55e8863702a2473faeb5b4db1dc32868",
            "90725aa82e7c4c489f7d6b36ae40e567",
            "c2121360c8e34b7fbbc55033312ce8bb",
            "a619b6ea347841109d033b823544e3e2",
            "585d5d7e036742de923dd17ff4063c14",
            "98db449b0f4a46db91ea83fb32789925",
            "d5ccb399b0a74c808e3b9021c0d1ca19",
            "e298ec3aa95a4b6aa30097077eaf9706",
            "55d5f7d84c794ff285ac01d816f3571b",
            "bbb9cab18d18471c9d8ceba28e576e76",
            "61006bd517b349608a9b491754759092",
            "4b66776f2ba247aab5a58fe7e07be8c8",
            "0588e535c80e4dbc973110f9306a8cad",
            "29c1350ef56b4547912c22d4698a6c6c",
            "1a733fbdc8c84248a480c6d578eff6ce",
            "b1a1b987b5a94cb7bb869e020eb7ccfe",
            "ce7871e0c6a84951bc446c59fd49f072",
            "871dcfdc19414e3ca9be5253368d1b54",
            "1748c7de097f4670a1d47ec43e679049",
            "a6b460bfdae24fe590d54b86bee88d57",
            "4e5275fc71484786a25070b7062fa074",
            "2d7d77ee07224c24b8ed9e19fa9b8255",
            "a76499970b984c4daed323153d407cad",
            "7da1939a80eb47a38b7939b865a37830",
            "ac3b5678d3df40ed857d24d52b2ce763",
            "98a49d0176b040858933a5168071b109",
            "4d009c41613644bf8aef8853c84f6e3d",
            "aa56380c577245deb4d7b7c594f95e05",
            "7258bbe260bb4857ba5840d78b5d9350",
            "c4be1feb785f4f9dbef8a0aeeb335cc0",
            "57f3a8ad7d1941f2a2032596d482f522",
            "7f53bdec5d3a4163beecd0014604af65",
            "9bf958ae19da4e9cbb4e6b212f11a364",
            "1d257a637ed5441a8f5cb98f6a0c7467",
            "e8e80678531d41bcb7aee26176ed72bd",
            "0c4c3e1d84624b8cb44b5d778e290d46",
            "d2ad57e85c1a408e8cbd96b04ca5c10c",
            "5f4db97186ee4ac7b3b16a4bee6d76ab",
            "50eac79c7fdd4f8ab8600dc414b379ec",
            "32bcf6da66e4426fb78606a5ecfb3838",
            "317659bbb18a42c2901605e125ce47f1",
            "f7898b52c5c94c2fa26e18d4ff7e9db7",
            "b166de73504f4183878c4080ac6f3279",
            "a9bb432c542c4e38a4770c0e0dbff7cf",
            "673fb4e5ceae4d6e8a0542183b9679dc",
            "2e6d8693ccaf4fe9b2ef4cac428dbeac",
            "7f61969b14c6400ea654bb39f6ef0ff8",
            "1d2086aebeb243479b1e82aaec992452",
            "ede4330cc46548f4aef6e3df3be3d84a",
            "2cbc3d6ec0b941e983b7bbdb47b7f307",
            "2f0dc14a40634fe6ac07c49d8e56d48a",
            "65a710c58f154e058cd38eaa03dd1262",
            "5d9d97af26bf4cd3b4dd8ee6a6ed5b2d",
            "cb274817720443adb9e79ddc1b0801c3",
            "0bc8ca645a3944948156e81b7c99b3ee",
            "bb50403432ec420f8b7c7bf227525db8",
            "cc675d54c988490f87cd9c65786660de",
            "4055bec2770442ab92f06175566205c7",
            "9c25381b12574192a3ee779963261e0b",
            "3525e56f72fe4da385855e01aa5d33e1",
            "d58e0aa08ba94f689d3dc23485c4e89e",
            "21fd7190191e413eb37f021cae60d90d",
            "8e4be4a6930b4377ac8e565430fc53d7",
            "18720484e3c94eb89356c90beb56f26e",
            "25f5b246f7904d50b9a446aaa95b59ff",
            "58f2594bb2f345ddbf519ba08511bfeb",
            "7538f544ba494a0ba7d8fdf88c91ff0f",
            "870faffe7f1548749e1b86d78b99b38f",
            "f05fc47f619c499d9095fa4edd3a5e99",
            "295b99e7a75648bfba95c5d27e3266f1",
            "fb5e41cf91fc4d3187e028f2d9b72970",
            "0b0c51c48d4e44738f6c935e043e1c19",
            "b76f840df45943b59bf570e030125abd",
            "1f25b894f9fc4770ae25025b243b05bd",
            "f343f93e0e264240a6d3206eaacbfa86",
            "0ac21d24326745dd8a77c8fba8eafc3a",
            "8aa7f73ca5d5449998ed9a2b3eeb4950",
            "4c46291ff8d54c27ae81a07d48596a11",
            "676a203d6ddf49f9b49e6676c4c33489",
            "4e229f829da14e27b6cb9373f888c5cc",
            "9a20414ce13a49c99693353ed0b6cb48",
            "9e8164defca44950b6ca2fa16da27d35",
            "902ff8f783114369b3bd52840781a385",
            "c4e93214e3d54078936241be2995bd41"
          ]
        },
        "id": "aFQTNS2giW1c",
        "outputId": "36c8cecb-4a92-4075-94a6-17fb3e3455a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hugging Face API Key found (last 4 chars for verification if needed: ...kFrX)\n",
            "Starting LLM Hallucination Experiment with ERIS vs PRNG...\n",
            "Loading LLM: mistralai/Mistral-7B-Instruct-v0.1...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba702c72d3644ca992060c0ac4ab789b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd083ec6ebf6414b96e6f06ed215e60e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53c9bb728c87411a84deceebf06195ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e298ec3aa95a4b6aa30097077eaf9706",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1748c7de097f4670a1d47ec43e679049",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4be1feb785f4f9dbef8a0aeeb335cc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "317659bbb18a42c2901605e125ce47f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65a710c58f154e058cd38eaa03dd1262",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e4be4a6930b4377ac8e565430fc53d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f25b894f9fc4770ae25025b243b05bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "import base64\n",
        "import math # For ceiling calculation\n",
        "import time # For delays\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# --- Configuration & API Key Handling ---\n",
        "try:\n",
        "    # Use Colab secrets if available\n",
        "    from google.colab import userdata\n",
        "    OCCYBYTE_API_KEY = userdata.get('OCCYBYTE_API_KEY')\n",
        "    HUGGINGFACE_API_KEY = userdata.get('HUGGINGFACE_API_KEY') # For Hugging Face Hub, if needed\n",
        "\n",
        "    if not OCCYBYTE_API_KEY:\n",
        "        print(\"Warning: OCCYBYTE_API_KEY secret found but is empty. Falling back to env var or placeholder.\")\n",
        "        OCCYBYTE_API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_OCCYBYTE_API_KEY_HERE\")\n",
        "    if not HUGGINGFACE_API_KEY:\n",
        "        print(\"Info: HUGGINGFACE_API_KEY secret found but is empty or not set. Using env var or proceeding without it (public models might not need it).\")\n",
        "        HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\") # Can be None\n",
        "\n",
        "except ImportError:\n",
        "    # Fallback for environments without google.colab\n",
        "    print(\"Warning: google.colab not found. Using environment variables or placeholders for API keys.\")\n",
        "    OCCYBYTE_API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_OCCYBYTE_API_KEY_HERE\")\n",
        "    HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\") # Can be None\n",
        "\n",
        "if OCCYBYTE_API_KEY == \"YOUR_OCCYBYTE_API_KEY_HERE\":\n",
        "    print(\"CRITICAL WARNING: Please set your OCCYBYTE_API_KEY in Colab secrets or as an environment variable.\")\n",
        "if HUGGINGFACE_API_KEY:\n",
        "    print(f\"Hugging Face API Key found (last 4 chars for verification if needed: ...{HUGGINGFACE_API_KEY[-4:] if len(HUGGINGFACE_API_KEY) > 4 else '****'})\")\n",
        "else:\n",
        "    print(\"Info: Hugging Face API Key not actively used in this script for public model loading, but fetched if provided.\")\n",
        "\n",
        "# ERIS API Configuration\n",
        "ERIS_BASE_URL = \"https://entropy.occybyte.com/api/eris/invoke\"\n",
        "ERIS_MAX_BYTES_PER_REQUEST = 16 * 1024 # 16384 bytes\n",
        "ERIS_REQUEST_TIMEOUT = 15\n",
        "ERIS_CHUNK_DELAY_SECONDS = 0.1\n",
        "ERIS_MAX_RETRIES = 3\n",
        "ERIS_RETRY_DELAY_SECONDS = 2\n",
        "ERIS_MIN_REQUEST_SIZE_WORKAROUND = 24 # As per your tested value\n",
        "\n",
        "# --- ERIS API Fetching Logic (Your Robust Functions) ---\n",
        "def fetch_quantum_bytes(total_bytes_needed: int, api_key: str) -> bytes | None:\n",
        "    \"\"\"\n",
        "    Fetches raw quantum bytes from the ERIS API, handling chunking, retries,\n",
        "    and adding a workaround for potential API base64 padding errors on small requests.\n",
        "    \"\"\"\n",
        "    # --- ACCESS GLOBAL CONSTANTS ---\n",
        "    # These are defined outside the function but used here.\n",
        "    # No 'global' keyword needed for reading them.\n",
        "    # ERIS_BASE_URL, ERIS_MAX_BYTES_PER_REQUEST, ERIS_REQUEST_TIMEOUT, etc.\n",
        "    # ERIS_MIN_REQUEST_SIZE_WORKAROUND\n",
        "\n",
        "    if not api_key or api_key == \"YOUR_OCCYBYTE_API_KEY_HERE\":\n",
        "        print(\"Error: Occybyte API Key not configured for fetch_quantum_bytes.\")\n",
        "        return None\n",
        "\n",
        "    if total_bytes_needed <= 0:\n",
        "        return b''\n",
        "\n",
        "    bytes_to_actually_request = total_bytes_needed\n",
        "    # CORRECTED LINE: Use the globally defined ERIS_MAX_BYTES_PER_REQUEST\n",
        "    if total_bytes_needed < ERIS_MAX_BYTES_PER_REQUEST and total_bytes_needed < ERIS_MIN_REQUEST_SIZE_WORKAROUND:\n",
        "        bytes_to_actually_request = ERIS_MIN_REQUEST_SIZE_WORKAROUND\n",
        "        print(f\"Workaround: Adjusted request size from {total_bytes_needed} to {bytes_to_actually_request} to potentially avoid API padding errors for small requests.\")\n",
        "\n",
        "    all_fetched_bytes = bytearray()\n",
        "    # CORRECTED LINE: Use the globally defined ERIS_MAX_BYTES_PER_REQUEST\n",
        "    num_chunks = math.ceil(bytes_to_actually_request / ERIS_MAX_BYTES_PER_REQUEST)\n",
        "\n",
        "\n",
        "    print(f\"Starting ERIS fetch for {total_bytes_needed} original bytes (requesting {bytes_to_actually_request} potentially due to workaround) in {num_chunks} chunk(s)...\")\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        bytes_remaining_to_request_overall = bytes_to_actually_request - len(all_fetched_bytes)\n",
        "        # CORRECTED LINE: Use the globally defined ERIS_MAX_BYTES_PER_REQUEST\n",
        "        bytes_to_request_this_chunk = min(bytes_remaining_to_request_overall, ERIS_MAX_BYTES_PER_REQUEST)\n",
        "\n",
        "\n",
        "        if bytes_to_request_this_chunk <= 0: break\n",
        "\n",
        "        # CORRECTED LINE: Use the globally defined ERIS_BASE_URL\n",
        "        url = f\"{ERIS_BASE_URL}?size={bytes_to_request_this_chunk}\"\n",
        "        headers = {\"X-API-Key\": api_key}\n",
        "        success = False\n",
        "\n",
        "        for attempt in range(ERIS_MAX_RETRIES + 1): # Use globally defined ERIS_MAX_RETRIES\n",
        "            try:\n",
        "                print(f\"  Requesting ERIS chunk {i+1}/{num_chunks} ({bytes_to_request_this_chunk} bytes), attempt {attempt+1}/{ERIS_MAX_RETRIES+1}...\")\n",
        "                 # Use globally defined ERIS_REQUEST_TIMEOUT\n",
        "                response = requests.get(url, headers=headers, timeout=ERIS_REQUEST_TIMEOUT)\n",
        "                response.raise_for_status()\n",
        "                json_response = response.json()\n",
        "\n",
        "                if \"data\" in json_response:\n",
        "                    base64_data = json_response[\"data\"]\n",
        "                    try:\n",
        "                         chunk_bytes = base64.b64decode(base64_data)\n",
        "                    except base64.binascii.Error as decode_error:\n",
        "                         raise ValueError(f\"Base64 decode failed: {decode_error}. API likely returned malformed data for size {bytes_to_request_this_chunk}.\")\n",
        "\n",
        "                    all_fetched_bytes.extend(chunk_bytes)\n",
        "                    print(f\"  Received {len(chunk_bytes)} bytes from ERIS. Total fetched so far: {len(all_fetched_bytes)}\")\n",
        "                    success = True\n",
        "                    break\n",
        "                else:\n",
        "                    raise ValueError(\"'data' field not found in ERIS API response\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ERIS Attempt {attempt+1} failed: {e}\")\n",
        "                if attempt < ERIS_MAX_RETRIES: # Use globally defined ERIS_MAX_RETRIES\n",
        "                    # Use globally defined ERIS_RETRY_DELAY_SECONDS\n",
        "                    print(f\"  Waiting {ERIS_RETRY_DELAY_SECONDS}s before retrying ERIS...\")\n",
        "                    time.sleep(ERIS_RETRY_DELAY_SECONDS)\n",
        "                else:\n",
        "                     print(f\"ERIS Chunk {i+1} failed after {ERIS_MAX_RETRIES+1} attempts. Aborting fetch.\")\n",
        "                     return None\n",
        "        if not success: return None\n",
        "        # Use globally defined ERIS_CHUNK_DELAY_SECONDS\n",
        "        if success and i < num_chunks - 1: time.sleep(ERIS_CHUNK_DELAY_SECONDS)\n",
        "\n",
        "\n",
        "    if len(all_fetched_bytes) < total_bytes_needed:\n",
        "        print(f\"Warning: Final ERIS fetched bytes ({len(all_fetched_bytes)}) less than originally required ({total_bytes_needed}). This might be okay if API returned slightly less than workaround request but still >= original.\")\n",
        "        if len(all_fetched_bytes) < total_bytes_needed:\n",
        "             print(f\"Error: Critical shortage. Fetched {len(all_fetched_bytes)}, needed {total_bytes_needed}.\")\n",
        "             return None\n",
        "\n",
        "    print(f\"Successfully fetched {len(all_fetched_bytes)} total bytes from ERIS (originally needed {total_bytes_needed}).\")\n",
        "    return bytes(all_fetched_bytes[:total_bytes_needed])\n",
        "\n",
        "def fetch_seed_from_eris(api_key: str, num_bytes: int = 4) -> int | None:\n",
        "    \"\"\"Fetches a specified number of quantum bytes from ERIS and converts them to an integer seed.\"\"\"\n",
        "    print(f\"Fetching {num_bytes} bytes from ERIS for seed generation...\")\n",
        "    seed_bytes = fetch_quantum_bytes(num_bytes, api_key)\n",
        "    if seed_bytes:\n",
        "        seed_int = int.from_bytes(seed_bytes, 'big') # Or 'little', ensure consistency\n",
        "        print(f\"ERIS seed bytes: {seed_bytes.hex()}, Integer seed: {seed_int}\")\n",
        "        return seed_int\n",
        "    print(\"Failed to fetch seed from ERIS.\")\n",
        "    return None\n",
        "\n",
        "# --- Quantum Choice Sampling Function (Included as per your example, though not directly used for seeding generate()) ---\n",
        "def quantum_choice_sampler(options: list, num_samples: int, api_key: str) -> list | None:\n",
        "    \"\"\"\n",
        "    Selects items from a list using quantum random bytes fetched via API.\n",
        "    Note: Uses simple modulo mapping, which may introduce slight bias\n",
        "          if len(options) does not evenly divide 256.\n",
        "    \"\"\"\n",
        "    if not options:\n",
        "        print(\"Error: Options list cannot be empty for quantum_choice_sampler.\")\n",
        "        return None\n",
        "    if num_samples <= 0:\n",
        "        print(\"Error: Number of samples must be positive for quantum_choice_sampler.\")\n",
        "        return None\n",
        "\n",
        "    all_quantum_bytes = fetch_quantum_bytes(num_samples, api_key)\n",
        "    if all_quantum_bytes is None:\n",
        "        print(\"Failed to fetch quantum bytes for sampling.\")\n",
        "        return None\n",
        "\n",
        "    if len(all_quantum_bytes) != num_samples: # Should be handled by fetch_quantum_bytes now\n",
        "        print(f\"Error: Byte count mismatch in quantum_choice_sampler. Expected {num_samples}, got {len(all_quantum_bytes)}.\")\n",
        "        return None\n",
        "\n",
        "    num_options = len(options)\n",
        "    selected_indices = [byte % num_options for byte in all_quantum_bytes]\n",
        "    return [options[i] for i in selected_indices]\n",
        "\n",
        "# --- LLM Configuration & Experiment ---\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"  # You can change this to other models like \"distilgpt2\", \"EleutherAI/pythia-70m\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", gpt2\n",
        "PRNG_FIXED_SEED = 42\n",
        "NUM_BYTES_FOR_ERIS_SEED = 4 # Standard integer size for many PRNG seeds\n",
        "\n",
        "# Generation parameters (keep consistent for fair comparison)\n",
        "MAX_NEW_TOKENS = 100\n",
        "TEMPERATURE = 0.7\n",
        "TOP_K = 50\n",
        "DO_SAMPLE = True # Important to actually use the randomness\n",
        "\n",
        "PROMPTS = [\n",
        "    \"The ancient prophecy spoke of a dragon that slept under the mountain, but it failed to mention\",\n",
        "    \"Explain the concept of recursion to a child using a story about a friendly robot.\",\n",
        "    \"Write a short poem about the silence of a winter forest.\",\n",
        "    \"What if the Roman Empire had access to basic steam power?\",\n",
        "    \"Generate a list of three unusual ingredients for a pizza.\"\n",
        "]\n",
        "\n",
        "def run_llm_experiment():\n",
        "    if OCCYBYTE_API_KEY == \"YOUR_OCCYBYTE_API_KEY_HERE\":\n",
        "        print(\"Cannot run experiment: Occybyte API Key is not set. Please configure it.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Loading LLM: {MODEL_NAME}...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=HUGGINGFACE_API_KEY)\n",
        "        model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, token=HUGGINGFACE_API_KEY) # Load model directly\n",
        "\n",
        "        if tokenizer.pad_token_id is None:\n",
        "            tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "        if model.config.pad_token_id is None:\n",
        "            model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "        # Move model to device if GPU available, Colab often provides one\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "        print(f\"LLM {MODEL_NAME} loaded successfully. Device: {device}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading LLM or Tokenizer: {e}\")\n",
        "        print(\"If this is a private or gated model, ensure your HUGGINGFACE_API_KEY is correctly set and has access.\")\n",
        "        return\n",
        "\n",
        "    for i, prompt_text in enumerate(PROMPTS):\n",
        "        print(f\"\\n--- Experiment for Prompt {i+1}/{len(PROMPTS)} ---\")\n",
        "        print(f\"Prompt: \\\"{prompt_text}\\\"\")\n",
        "\n",
        "        # Remove 'generator' from common_generation_args as it's not used by gpt2's generate kwargs\n",
        "        common_generation_args = {\n",
        "            \"max_new_tokens\": MAX_NEW_TOKENS,\n",
        "            \"temperature\": TEMPERATURE,\n",
        "            \"top_k\": TOP_K,\n",
        "            \"do_sample\": DO_SAMPLE,\n",
        "            \"pad_token_id\": model.config.pad_token_id # Use model's pad_token_id\n",
        "            # Add other consistent parameters here e.g. top_p\n",
        "        }\n",
        "\n",
        "        input_ids = tokenizer(prompt_text, return_tensors=\"pt\").input_ids.to(device) # Move inputs to the same device as model\n",
        "        common_generation_args[\"max_length\"] = input_ids.shape[1] + MAX_NEW_TOKENS # Optional: Be explicit\n",
        "\n",
        "\n",
        "        # --- ERIS Seeded Generation ---\n",
        "        print(\"\\nGenerating with ERIS Seed...\")\n",
        "        eris_seed_integer = fetch_seed_from_eris(OCCYBYTE_API_KEY, NUM_BYTES_FOR_ERIS_SEED)\n",
        "        if eris_seed_integer is not None:\n",
        "            try:\n",
        "                print(f\"  Setting global torch seed to ERIS-derived: {eris_seed_integer}\")\n",
        "                torch.manual_seed(eris_seed_integer) # Set global seed for PyTorch\n",
        "                # Ensure all parts of torch use this, including CUDA if enabled\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.manual_seed_all(eris_seed_integer)\n",
        "\n",
        "                # Inside your loop, before model.generate\n",
        "                tokenized_inputs = tokenizer(prompt_text, return_tensors=\"pt\", padding=True, truncation=True) # Add padding & truncation\n",
        "                input_ids = tokenized_inputs.input_ids.to(device)\n",
        "                attention_mask = tokenized_inputs.attention_mask.to(device) # Get the attention mask\n",
        "\n",
        "                eris_output_ids = model.generate(\n",
        "                    input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    **common_generation_args\n",
        "                )\n",
        "                eris_generated_text = tokenizer.decode(eris_output_ids[0], skip_special_tokens=True)\n",
        "                print(f\"ERIS Output:\\n{eris_generated_text}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error during ERIS seeded generation: {e}\")\n",
        "        else:\n",
        "            print(\"Could not generate with ERIS seed as seed fetching failed.\")\n",
        "\n",
        "        # --- PRNG Seeded Generation ---\n",
        "        print(\"\\nGenerating with PRNG Fixed Seed...\")\n",
        "        try:\n",
        "            print(f\"  Setting global torch seed to PRNG fixed: {PRNG_FIXED_SEED}\")\n",
        "            torch.manual_seed(PRNG_FIXED_SEED) # Set global seed for PyTorch\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.manual_seed_all(PRNG_FIXED_SEED)\n",
        "\n",
        "\n",
        "            prng_output_ids = model.generate(\n",
        "                input_ids,\n",
        "                # No 'generator' kwarg here\n",
        "                **common_generation_args\n",
        "            )\n",
        "            prng_generated_text = tokenizer.decode(prng_output_ids[0], skip_special_tokens=True)\n",
        "            print(f\"PRNG Output:\\n{prng_generated_text}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during PRNG seeded generation: {e}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting LLM Hallucination Experiment with ERIS vs PRNG...\")\n",
        "    run_llm_experiment()\n",
        "\n",
        "    # Example of using your quantum_choice_sampler (not tied to LLM here, just to show it runs)\n",
        "    print(\"\\n--- Example of quantum_choice_sampler (separate from LLM demo) ---\")\n",
        "    if OCCYBYTE_API_KEY != \"YOUR_OCCYBYTE_API_KEY_HERE\":\n",
        "        potential_tokens = [\"alpha\", \"beta\", \"gamma\", \"delta\", \"epsilon\", \"zeta\", \"eta\", \"theta\"]\n",
        "        num_choices_to_make = 5\n",
        "        print(f\"Attempting to select {num_choices_to_make} items from {potential_tokens} using ERIS quantum randomness...\")\n",
        "        selected_items = quantum_choice_sampler(potential_tokens, num_choices_to_make, OCCYBYTE_API_KEY)\n",
        "        if selected_items:\n",
        "            print(f\"Quantum-selected items ({len(selected_items)}): {selected_items}\")\n",
        "        else:\n",
        "            print(\"Failed to select items using quantum_choice_sampler.\")\n",
        "    else:\n",
        "        print(\"Skipping quantum_choice_sampler example as Occybyte API key is not set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5_B1u_L9HvD"
      },
      "source": [
        "The bits and bytes version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4996d3d1fde249a4a3075759559f1ec2",
            "d990a7f2b1b24955b7cc3d3592663c0a",
            "5e6e7c258b38406abbbdd41b371d8477",
            "d1f559c8bc1a47eaae6d2b36d0593974",
            "b59a1c45b10d4c989c419bac3261fa79",
            "a5491b2f1bd14c63981d88d6a294858b",
            "9eb0909db4344547a0099f9f91bdbd32",
            "59b40d98e73141ea9d50adc9fb4002a6",
            "f79e9aae4ebf4d019e15209c04d7dfae",
            "ad43b2c825a24c149718cf724552150c",
            "95b2a4083dcb40ba87e5a53a9bffacf4"
          ]
        },
        "id": "YN-IpvZ99JQr",
        "outputId": "40beb0fb-598d-473e-e1be-c1db5cd84cf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformers version: 4.51.3\n",
            "Accelerate version: 1.6.0\n",
            "BitsAndBytes version: 0.45.5\n",
            "Required libraries are already available.\n",
            "Hugging Face API Key found (Token for model access).\n",
            "Running in Google Colab. Ensure your runtime type is set to GPU for BitsAndBytes quantization.\n",
            "GPU detected by PyTorch: Tesla T4\n",
            "Starting LLM Experiment with ERIS vs PRNG...\n",
            "******************** GPU Check ********************\n",
            "CUDA is available! PyTorch CUDA version: 12.4\n",
            "GPU detected: Tesla T4\n",
            "**************************************************\n",
            "Attempting to load LLM: mistralai/Mistral-7B-Instruct-v0.1 with 8-bit quantization...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4996d3d1fde249a4a3075759559f1ec2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM mistralai/Mistral-7B-Instruct-v0.1 loaded successfully with 8-bit quantization.\n",
            "Model is on device: cuda:0\n",
            "\n",
            "--- Experiment for Prompt 1/3 ---\n",
            "Prompt: \"The ancient prophecy spoke of a dragon that slept under the mountain, but it failed to mention\"\n",
            "Using tokenizer_max_len: 32768 for prompt tokenization.\n",
            "\n",
            "Generating with ERIS Seed...\n",
            "Workaround: Adjusted request size from 4 to 24 for ERIS.\n",
            "ERIS seed bytes: b28a043b, Integer seed: 2995389499\n",
            "  Setting global torch seed to ERIS-derived: 2995389499\n",
            "ERIS Output:\n",
            "The ancient prophecy spoke of a dragon that slept under the mountain, but it failed to mention that the dragon was a woman.\n",
            "\n",
            "Aria was awakened by the pain of a man's hand on her throat, his other hand gripping her wrist. She pried his fingers away and turned to face him, her eyes glowing amber. The man was terrified, and she didn't blame him. Aria was a dragon, and she'd been asleep for a thousand years.\n",
            "\n",
            "But she wasn't angry. She was curious. Who had disturbed her slumber? And why did he think she was a dragon?\n",
            "\n",
            "Aria waited until the man was gone before rising from her bed of stone. She looked around the cavern, taking note of the other creatures that called it\n",
            "\n",
            "Generating with PRNG Fixed Seed...\n",
            "  Setting global torch seed to PRNG fixed: 42\n",
            "PRNG Output:\n",
            "The ancient prophecy spoke of a dragon that slept under the mountain, but it failed to mention that the dragon was also guarding a treasure beyond imagination. When a group of adventurers arrived at the mountain, they knew they had to find the treasure, but they also knew that they must defeat the dragon first. They armed themselves and began the perilous journey to the top of the mountain.\n",
            "\n",
            "As they climbed higher and higher, they could feel the dragon's presence, but they refused to give up. They faced countless obstacles, from treacherous cliffs to dark caves, but they persevered through it all. Finally, they reached the dragon's lair, where they faced the beast itself.\n",
            "\n",
            "The dragon was a fearsome creature, with scales as black as night and eyes that\n",
            "----------------------------------------\n",
            "\n",
            "--- Experiment for Prompt 2/3 ---\n",
            "Prompt: \"Explain the concept of recursion to a child using a story about a friendly robot.\"\n",
            "Using tokenizer_max_len: 32768 for prompt tokenization.\n",
            "\n",
            "Generating with ERIS Seed...\n",
            "Workaround: Adjusted request size from 4 to 24 for ERIS.\n",
            "ERIS seed bytes: ee2ac206, Integer seed: 3995779590\n",
            "  Setting global torch seed to ERIS-derived: 3995779590\n",
            "ERIS Output:\n",
            "Explain the concept of recursion to a child using a story about a friendly robot.\n",
            "\n",
            "Once upon a time, there was a friendly robot named Robby. Robby loved to play with his balls, but he had a problem. Whenever he tried to catch one, the ball would always bounce away, no matter how hard he tried.\n",
            "\n",
            "One day, Robby met a wise old computer who told him about a special trick called recursion. The old computer explained that recursion was like calling on a friend to help you do something, but your friend calls on you to help him do the same thing first.\n",
            "\n",
            "Robby thought about this for a moment, and then he had an idea. He decided to program his robot so that whenever he caught a ball, he would throw it up into the air\n",
            "\n",
            "Generating with PRNG Fixed Seed...\n",
            "  Setting global torch seed to PRNG fixed: 42\n",
            "PRNG Output:\n",
            "Explain the concept of recursion to a child using a story about a friendly robot.\n",
            "\n",
            "Once upon a time, in a land far, far away, there was a friendly robot named Robby. Robby was a special robot because he had the ability to do something called recursion.\n",
            "\n",
            "Now, you might be wondering what recursion means, and that's okay! It's a big word, but we'll do our best to explain it in a way that's easy to understand.\n",
            "\n",
            "Recursion is like when Robby does something over and over again, but each time he does it, he does it a little bit differently. It's kind of like when you build a tower out of blocks. Each block you add to the top of the tower is a little bit different\n",
            "----------------------------------------\n",
            "\n",
            "--- Experiment for Prompt 3/3 ---\n",
            "Prompt: \"Write a short poem about the silence of a winter forest.\"\n",
            "Using tokenizer_max_len: 32768 for prompt tokenization.\n",
            "\n",
            "Generating with ERIS Seed...\n",
            "Workaround: Adjusted request size from 4 to 24 for ERIS.\n",
            "ERIS seed bytes: dbe64b13, Integer seed: 3689302803\n",
            "  Setting global torch seed to ERIS-derived: 3689302803\n",
            "ERIS Output:\n",
            "Write a short poem about the silence of a winter forest.\n",
            "\n",
            "Amidst the snowy trees,\n",
            "A silence reigns with ease,\n",
            "The only sounds are crunching underfoot,\n",
            "As winter weaves its icy spell.\n",
            "\n",
            "The branches, bare and brittle,\n",
            "Whisper secrets to each other,\n",
            "In a language only they understand,\n",
            "A language of stillness and peace.\n",
            "\n",
            "The forest, once alive with rustling leaves,\n",
            "Now holds its breath in the chill of the freeze,\n",
            "A moment of calm in a world of commotion,\n",
            "A moment to find peace and serenity.\n",
            "\n",
            "So let us walk amidst the winter wonder,\n",
            "And listen to the hush of the forest's slumber,\n",
            "\n",
            "\n",
            "Generating with PRNG Fixed Seed...\n",
            "  Setting global torch seed to PRNG fixed: 42\n",
            "PRNG Output:\n",
            "Write a short poem about the silence of a winter forest.\n",
            "\n",
            "In the hush of winter's slumber,\n",
            "Where the snowflakes gently tumble,\n",
            "A forest holds its breath in silence,\n",
            "Its secret whispers, lost in silence.\n",
            "\n",
            "The trees stand tall and bare,\n",
            "Their branches dressed in white attire,\n",
            "A winter wonderland of beauty,\n",
            "Wrapped in a cloak of tranquility.\n",
            "\n",
            "The only sound is the crunch\n",
            "Of snow beneath the boots' tough grasp,\n",
            "As we wander through this frozen realm,\n",
            "Our footprints the only trace, a fleeting tale.\n",
            "\n",
            "In the quiet of the winter forest,\n",
            "We find solace from life's relentless task,\n",
            "As\n",
            "----------------------------------------\n",
            "\n",
            "--- Example of quantum_choice_sampler (separate from LLM demo) ---\n",
            "Attempting to select 5 items from ['alpha', 'beta', 'gamma', 'delta', 'epsilon', 'zeta', 'eta', 'theta'] using ERIS quantum randomness...\n",
            "Workaround: Adjusted request size from 5 to 24 for ERIS.\n",
            "Quantum-selected items (5): ['theta', 'theta', 'beta', 'delta', 'zeta']\n"
          ]
        }
      ],
      "source": [
        "# --- Essential Library Installation ---\n",
        "# Best to run this in a separate cell at the very top of your Colab notebook.\n",
        "# After running this, YOU MUST RESTART THE RUNTIME if bitsandbytes or accelerate were newly installed or updated.\n",
        "# Go to \"Runtime\" -> \"Restart runtime\" in the Colab menu.\n",
        "try:\n",
        "    import bitsandbytes\n",
        "    import accelerate\n",
        "    import transformers\n",
        "    print(f\"Transformers version: {transformers.__version__}\")\n",
        "    print(f\"Accelerate version: {accelerate.__version__}\")\n",
        "    print(f\"BitsAndBytes version: {bitsandbytes.__version__}\")\n",
        "    print(\"Required libraries are already available.\")\n",
        "except ImportError as e:\n",
        "    print(f\"Missing one or more libraries ({e}). Installing...\")\n",
        "    # In Colab, use !pip install.\n",
        "    if \"google.colab\" in str(get_ipython()): # type: ignore\n",
        "        get_ipython().system('pip install transformers accelerate bitsandbytes --upgrade') # type: ignore\n",
        "        print(\"Installation complete. IMPORTANT: PLEASE RESTART THE RUNTIME NOW (Runtime -> Restart runtime).\")\n",
        "        # Exit to force user to restart and re-run for new libraries to take effect.\n",
        "        # This is a bit aggressive but helps avoid issues with bitsandbytes not finding CUDA.\n",
        "        import os\n",
        "        os._exit(0)\n",
        "    else:\n",
        "        print(\"Please install missing libraries manually: pip install transformers accelerate bitsandbytes --upgrade\")\n",
        "        import sys\n",
        "        sys.exit(\"Missing required libraries for non-Colab environment.\")\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import base64\n",
        "import math # For ceiling calculation\n",
        "import time # For delays\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig # Import BitsAndBytesConfig\n",
        "\n",
        "# --- Configuration & API Key Handling ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    OCCYBYTE_API_KEY = userdata.get('OCCYBYTE_API_KEY')\n",
        "    HUGGINGFACE_API_KEY = userdata.get('HUGGINGFACE_API_KEY')\n",
        "    if not OCCYBYTE_API_KEY:\n",
        "        print(\"Warning: OCCYBYTE_API_KEY secret found but is empty. Falling back to env var or placeholder.\")\n",
        "        OCCYBYTE_API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_OCCYBYTE_API_KEY_HERE\")\n",
        "    if not HUGGINGFACE_API_KEY:\n",
        "        print(\"Info: HUGGINGFACE_API_KEY secret not found or empty. Using env var or proceeding without it.\")\n",
        "        HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
        "except ImportError:\n",
        "    print(\"Warning: google.colab not found. Using environment variables for API keys.\")\n",
        "    OCCYBYTE_API_KEY = os.getenv(\"OCCYBYTE_API_KEY\", \"YOUR_OCCYBYTE_API_KEY_HERE\")\n",
        "    HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
        "\n",
        "if OCCYBYTE_API_KEY == \"YOUR_OCCYBYTE_API_KEY_HERE\":\n",
        "    print(\"CRITICAL WARNING: Please set your OCCYBYTE_API_KEY in Colab secrets or as an environment variable.\")\n",
        "if HUGGINGFACE_API_KEY:\n",
        "    print(f\"Hugging Face API Key found (Token for model access).\")\n",
        "else:\n",
        "    print(\"Info: Hugging Face API Key not found. Access to gated models might fail.\")\n",
        "\n",
        "# ERIS API Configuration (remains the same)\n",
        "ERIS_BASE_URL = \"https://entropy.occybyte.com/api/eris/invoke\"\n",
        "ERIS_MAX_BYTES_PER_REQUEST = 16 * 1024\n",
        "ERIS_REQUEST_TIMEOUT = 15\n",
        "ERIS_CHUNK_DELAY_SECONDS = 0.1\n",
        "ERIS_MAX_RETRIES = 3\n",
        "ERIS_RETRY_DELAY_SECONDS = 2\n",
        "ERIS_MIN_REQUEST_SIZE_WORKAROUND = 24\n",
        "\n",
        "# --- ERIS API Fetching Logic (remains the same) ---\n",
        "def fetch_quantum_bytes(total_bytes_needed: int, api_key: str) -> bytes | None:\n",
        "    if not api_key or api_key == \"YOUR_OCCYBYTE_API_KEY_HERE\":\n",
        "        print(\"Error: Occybyte API Key not configured for fetch_quantum_bytes.\")\n",
        "        return None\n",
        "    if total_bytes_needed <= 0: return b''\n",
        "    bytes_to_actually_request = total_bytes_needed\n",
        "    if total_bytes_needed < ERIS_MAX_BYTES_PER_REQUEST and total_bytes_needed < ERIS_MIN_REQUEST_SIZE_WORKAROUND:\n",
        "        bytes_to_actually_request = ERIS_MIN_REQUEST_SIZE_WORKAROUND\n",
        "        print(f\"Workaround: Adjusted request size from {total_bytes_needed} to {bytes_to_actually_request} for ERIS.\")\n",
        "    all_fetched_bytes = bytearray()\n",
        "    num_chunks = math.ceil(bytes_to_actually_request / ERIS_MAX_BYTES_PER_REQUEST)\n",
        "    # print(f\"Starting ERIS fetch for {total_bytes_needed} original bytes (requesting {bytes_to_actually_request}) in {num_chunks} chunk(s)...\")\n",
        "    for i in range(num_chunks):\n",
        "        bytes_remaining_to_request_overall = bytes_to_actually_request - len(all_fetched_bytes)\n",
        "        bytes_to_request_this_chunk = min(bytes_remaining_to_request_overall, ERIS_MAX_BYTES_PER_REQUEST)\n",
        "        if bytes_to_request_this_chunk <= 0: break\n",
        "        url = f\"{ERIS_BASE_URL}?size={bytes_to_request_this_chunk}\"\n",
        "        headers = {\"X-API-Key\": api_key}\n",
        "        success = False\n",
        "        for attempt in range(ERIS_MAX_RETRIES + 1):\n",
        "            try:\n",
        "                # print(f\"  Requesting ERIS chunk {i+1}/{num_chunks} ({bytes_to_request_this_chunk} bytes), attempt {attempt+1}/{ERIS_MAX_RETRIES+1}...\")\n",
        "                response = requests.get(url, headers=headers, timeout=ERIS_REQUEST_TIMEOUT)\n",
        "                response.raise_for_status()\n",
        "                json_response = response.json()\n",
        "                if \"data\" in json_response:\n",
        "                    base64_data = json_response[\"data\"]\n",
        "                    try: chunk_bytes = base64.b64decode(base64_data)\n",
        "                    except base64.binascii.Error as decode_error: raise ValueError(f\"Base64 decode failed: {decode_error}.\")\n",
        "                    all_fetched_bytes.extend(chunk_bytes)\n",
        "                    # print(f\"  Received {len(chunk_bytes)} bytes from ERIS. Total: {len(all_fetched_bytes)}\")\n",
        "                    success = True\n",
        "                    break\n",
        "                else: raise ValueError(\"'data' field not found in ERIS API response\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ERIS Attempt {attempt+1} failed for chunk {i+1}: {e}\")\n",
        "                if attempt < ERIS_MAX_RETRIES: time.sleep(ERIS_RETRY_DELAY_SECONDS)\n",
        "                else: print(f\"ERIS Chunk {i+1} failed. Aborting.\"); return None\n",
        "        if not success: return None\n",
        "        if success and i < num_chunks - 1: time.sleep(ERIS_CHUNK_DELAY_SECONDS)\n",
        "    if len(all_fetched_bytes) < total_bytes_needed:\n",
        "        # This warning was a bit confusing, let's clarify.\n",
        "        # If workaround requested more, but API gave less than workaround but MORE than original, it's fine.\n",
        "        # The real error is if final_bytes_to_return (after slicing) is less than total_bytes_needed\n",
        "        pass # Slicing at the end handles this.\n",
        "\n",
        "    final_bytes_to_return = bytes(all_fetched_bytes[:total_bytes_needed])\n",
        "    if len(final_bytes_to_return) < total_bytes_needed:\n",
        "        print(f\"Error: Critical shortage. Fetched enough raw ({len(all_fetched_bytes)}) but after slicing for original {total_bytes_needed}, got {len(final_bytes_to_return)}.\")\n",
        "        return None\n",
        "    # print(f\"Successfully fetched and processed {len(final_bytes_to_return)} bytes for ERIS (originally needed {total_bytes_needed}).\")\n",
        "    return final_bytes_to_return\n",
        "\n",
        "def fetch_seed_from_eris(api_key: str, num_bytes: int = 4) -> int | None:\n",
        "    # print(f\"Fetching {num_bytes} bytes from ERIS for seed generation...\") # Reduced verbosity\n",
        "    seed_bytes = fetch_quantum_bytes(num_bytes, api_key)\n",
        "    if seed_bytes:\n",
        "        seed_int = int.from_bytes(seed_bytes, 'big')\n",
        "        print(f\"ERIS seed bytes: {seed_bytes.hex()}, Integer seed: {seed_int}\")\n",
        "        return seed_int\n",
        "    print(\"Failed to fetch seed from ERIS.\")\n",
        "    return None\n",
        "\n",
        "def quantum_choice_sampler(options: list, num_samples: int, api_key: str) -> list | None:\n",
        "    if not options: print(\"Error: Options list empty for quantum_choice_sampler.\"); return None\n",
        "    if num_samples <= 0: print(\"Error: Num samples must be positive for quantum_choice_sampler.\"); return None\n",
        "    all_quantum_bytes = fetch_quantum_bytes(num_samples, api_key)\n",
        "    if all_quantum_bytes is None: print(\"Failed to fetch quantum bytes for sampling.\"); return None\n",
        "    if len(all_quantum_bytes) != num_samples: print(f\"Error: Byte count mismatch for quantum_choice_sampler. Expected {num_samples}, got {len(all_quantum_bytes)}.\"); return None\n",
        "    num_options = len(options)\n",
        "    selected_indices = [byte % num_options for byte in all_quantum_bytes]\n",
        "    return [options[i] for i in selected_indices]\n",
        "\n",
        "# --- LLM Configuration & Experiment ---\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "PRNG_FIXED_SEED = 42\n",
        "NUM_BYTES_FOR_ERIS_SEED = 4\n",
        "MAX_NEW_TOKENS = 150 # Reduced for Mistral 7B to manage memory/time\n",
        "TEMPERATURE = 0.7\n",
        "TOP_K = 50\n",
        "DO_SAMPLE = True\n",
        "\n",
        "PROMPTS = [\n",
        "    \"The ancient prophecy spoke of a dragon that slept under the mountain, but it failed to mention\",\n",
        "    \"Explain the concept of recursion to a child using a story about a friendly robot.\",\n",
        "    \"Write a short poem about the silence of a winter forest.\",\n",
        "    # \"What if the Roman Empire had access to basic steam power?\", # Keeping prompts fewer for faster iteration\n",
        "    # \"Generate a list of three unusual ingredients for a pizza.\"\n",
        "]\n",
        "\n",
        "model_loaded_globally = False # Flag to track if model is loaded\n",
        "\n",
        "def load_model_and_tokenizer_once():\n",
        "    global model, tokenizer, device, model_loaded_globally # Allow modification of global variables\n",
        "\n",
        "    if model_loaded_globally:\n",
        "        # print(f\"Model {MODEL_NAME} and tokenizer already loaded.\") # Reduced verbosity\n",
        "        return True\n",
        "\n",
        "    print(\"*\"*20 + \" GPU Check \" + \"*\"*20)\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"CRITICAL ERROR: CUDA (GPU) is not available for PyTorch.\")\n",
        "        print(\"BitsAndBytes 8-bit quantization requires a GPU runtime.\")\n",
        "        print(\"Please go to 'Runtime' -> 'Change runtime type' and select a GPU hardware accelerator.\")\n",
        "        return False\n",
        "    else:\n",
        "        print(f\"CUDA is available! PyTorch CUDA version: {torch.version.cuda}\")\n",
        "        print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"*\"*50)\n",
        "\n",
        "    print(f\"Attempting to load LLM: {MODEL_NAME} with 8-bit quantization...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            token=HUGGINGFACE_API_KEY,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # --- Updated Quantization Config ---\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_8bit=True\n",
        "        )\n",
        "\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            token=HUGGINGFACE_API_KEY,\n",
        "            trust_remote_code=True,\n",
        "            quantization_config=quantization_config, # Use BitsAndBytesConfig object\n",
        "            device_map=\"auto\"       # Let accelerate handle device mapping\n",
        "        )\n",
        "\n",
        "        if tokenizer.pad_token_id is None:\n",
        "            # print(f\"Tokenizer pad_token_id is None, setting to eos_token_id: {tokenizer.eos_token_id}\")\n",
        "            tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "        # For Mistral, this is usually handled well by the model config.\n",
        "        # if model.config.pad_token_id is None:\n",
        "        # model.config.pad_token_id = tokenizer.eos_token_id # Use tokenizer's for consistency\n",
        "\n",
        "        print(f\"LLM {MODEL_NAME} loaded successfully with 8-bit quantization.\")\n",
        "        device = next(model.parameters()).device # Get device from model after device_map\n",
        "        print(f\"Model is on device: {device}\")\n",
        "        model_loaded_globally = True\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading LLM or Tokenizer ({MODEL_NAME}): {e}\")\n",
        "        print(\"Ensure HUGGINGFACE_API_KEY is correctly set and has access if it's a gated model.\")\n",
        "        print(\"Make sure 'bitsandbytes' and 'accelerate' are installed and your runtime has enough RAM/GPU.\")\n",
        "        print(\"If you just installed libraries, YOU MUST RESTART THE RUNTIME (Runtime -> Restart runtime).\")\n",
        "        return False\n",
        "\n",
        "def run_llm_experiment():\n",
        "    global device, tokenizer, model # Ensure we are using the globally loaded tokenizer and model\n",
        "\n",
        "    if OCCYBYTE_API_KEY == \"YOUR_OCCYBYTE_API_KEY_HERE\":\n",
        "        print(\"Cannot run experiment: Occybyte API Key is not set.\")\n",
        "        return\n",
        "\n",
        "    if not load_model_and_tokenizer_once(): # This function now sets global tokenizer and model\n",
        "        print(\"Model loading failed. Aborting experiment.\")\n",
        "        return\n",
        "\n",
        "    for i, prompt_text in enumerate(PROMPTS):\n",
        "        print(f\"\\n--- Experiment for Prompt {i+1}/{len(PROMPTS)} ---\")\n",
        "        print(f\"Prompt: \\\"{prompt_text}\\\"\")\n",
        "\n",
        "        if hasattr(tokenizer, 'model_max_length') and isinstance(tokenizer.model_max_length, int) and tokenizer.model_max_length < 1e10:\n",
        "            tokenizer_max_len = tokenizer.model_max_length\n",
        "        elif hasattr(model.config, 'max_position_embeddings') and isinstance(model.config.max_position_embeddings, int):\n",
        "            tokenizer_max_len = model.config.max_position_embeddings\n",
        "        else:\n",
        "            tokenizer_max_len = 512\n",
        "        print(f\"Using tokenizer_max_len: {tokenizer_max_len} for prompt tokenization.\")\n",
        "\n",
        "        tokenized_inputs = tokenizer(\n",
        "            prompt_text,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=tokenizer_max_len\n",
        "        )\n",
        "        input_ids = tokenized_inputs.input_ids.to(device)\n",
        "        attention_mask = tokenized_inputs.attention_mask.to(device)\n",
        "\n",
        "        common_generation_args = {\n",
        "            \"max_new_tokens\": MAX_NEW_TOKENS,\n",
        "            \"temperature\": TEMPERATURE,\n",
        "            \"top_k\": TOP_K,\n",
        "            \"do_sample\": DO_SAMPLE,\n",
        "            \"pad_token_id\": tokenizer.eos_token_id,\n",
        "            \"attention_mask\": attention_mask\n",
        "        }\n",
        "\n",
        "        # --- ERIS Seeded Generation ---\n",
        "        print(\"\\nGenerating with ERIS Seed...\")\n",
        "        eris_seed_integer = fetch_seed_from_eris(OCCYBYTE_API_KEY, NUM_BYTES_FOR_ERIS_SEED)\n",
        "        if eris_seed_integer is not None:\n",
        "            try:\n",
        "                print(f\"  Setting global torch seed to ERIS-derived: {eris_seed_integer}\")\n",
        "                torch.manual_seed(eris_seed_integer)\n",
        "                if torch.cuda.is_available(): torch.cuda.manual_seed_all(eris_seed_integer)\n",
        "\n",
        "                eris_output_ids = model.generate(input_ids, **common_generation_args)\n",
        "                eris_generated_text = tokenizer.decode(eris_output_ids[0], skip_special_tokens=True)\n",
        "                print(f\"ERIS Output:\\n{eris_generated_text}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error during ERIS seeded generation: {e}\")\n",
        "        else:\n",
        "            print(\"Could not generate with ERIS seed as seed fetching failed.\")\n",
        "\n",
        "        # --- PRNG Seeded Generation ---\n",
        "        print(\"\\nGenerating with PRNG Fixed Seed...\")\n",
        "        try:\n",
        "            print(f\"  Setting global torch seed to PRNG fixed: {PRNG_FIXED_SEED}\")\n",
        "            torch.manual_seed(PRNG_FIXED_SEED)\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.manual_seed_all(PRNG_FIXED_SEED) # <<< CORRECTED LINE\n",
        "\n",
        "            prng_output_ids = model.generate(input_ids, **common_generation_args)\n",
        "            prng_generated_text = tokenizer.decode(prng_output_ids[0], skip_special_tokens=True)\n",
        "            print(f\"PRNG Output:\\n{prng_generated_text}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during PRNG seeded generation: {e}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # This check is crucial for Colab.\n",
        "    if \"google.colab\" in str(get_ipython()): # type: ignore\n",
        "        print(\"Running in Google Colab. Ensure your runtime type is set to GPU for BitsAndBytes quantization.\")\n",
        "        if not torch.cuda.is_available():\n",
        "            print(\"WARNING: GPU NOT DETECTED BY PYTORCH. BitsAndBytes will likely fail.\")\n",
        "            print(\"Go to 'Runtime' -> 'Change runtime type' and select GPU as Hardware Accelerator.\")\n",
        "        else:\n",
        "            print(f\"GPU detected by PyTorch: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    print(\"Starting LLM Experiment with ERIS vs PRNG...\")\n",
        "    run_llm_experiment()\n",
        "\n",
        "    # quantum_choice_sampler example (remains the same)\n",
        "    print(\"\\n--- Example of quantum_choice_sampler (separate from LLM demo) ---\")\n",
        "    if OCCYBYTE_API_KEY != \"YOUR_OCCYBYTE_API_KEY_HERE\":\n",
        "        # ... (rest of  quantum_choice_sampler example call) ...\n",
        "        potential_tokens = [\"alpha\", \"beta\", \"gamma\", \"delta\", \"epsilon\", \"zeta\", \"eta\", \"theta\"]\n",
        "        num_choices_to_make = 5\n",
        "        print(f\"Attempting to select {num_choices_to_make} items from {potential_tokens} using ERIS quantum randomness...\")\n",
        "        selected_items = quantum_choice_sampler(potential_tokens, num_choices_to_make, OCCYBYTE_API_KEY)\n",
        "        if selected_items: print(f\"Quantum-selected items ({len(selected_items)}): {selected_items}\")\n",
        "        else: print(\"Failed to select items using quantum_choice_sampler.\")\n",
        "    else:\n",
        "        print(\"Skipping quantum_choice_sampler example as Occybyte API key is not set.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00104ad662484e6ca6de32af8133e18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0588e535c80e4dbc973110f9306a8cad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac21d24326745dd8a77c8fba8eafc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a20414ce13a49c99693353ed0b6cb48",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e8164defca44950b6ca2fa16da27d35",
            "value": 0
          }
        },
        "0b0c51c48d4e44738f6c935e043e1c19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc8ca645a3944948156e81b7c99b3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d58e0aa08ba94f689d3dc23485c4e89e",
            "placeholder": "​",
            "style": "IPY_MODEL_21fd7190191e413eb37f021cae60d90d",
            "value": " 9.94G/9.94G [02:04&lt;00:00, 139MB/s]"
          }
        },
        "0c4c3e1d84624b8cb44b5d778e290d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1748c7de097f4670a1d47ec43e679049": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6b460bfdae24fe590d54b86bee88d57",
              "IPY_MODEL_4e5275fc71484786a25070b7062fa074",
              "IPY_MODEL_2d7d77ee07224c24b8ed9e19fa9b8255"
            ],
            "layout": "IPY_MODEL_a76499970b984c4daed323153d407cad"
          }
        },
        "18720484e3c94eb89356c90beb56f26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_870faffe7f1548749e1b86d78b99b38f",
            "placeholder": "​",
            "style": "IPY_MODEL_f05fc47f619c499d9095fa4edd3a5e99",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "1a733fbdc8c84248a480c6d578eff6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d2086aebeb243479b1e82aaec992452": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d257a637ed5441a8f5cb98f6a0c7467": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f25b894f9fc4770ae25025b243b05bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f343f93e0e264240a6d3206eaacbfa86",
              "IPY_MODEL_0ac21d24326745dd8a77c8fba8eafc3a",
              "IPY_MODEL_8aa7f73ca5d5449998ed9a2b3eeb4950"
            ],
            "layout": "IPY_MODEL_4c46291ff8d54c27ae81a07d48596a11"
          }
        },
        "21fd7190191e413eb37f021cae60d90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2372ff956f2c47e4a67fd80d5235919d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23917413a3bb4427b5ef7a6379f2f59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25f5b246f7904d50b9a446aaa95b59ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295b99e7a75648bfba95c5d27e3266f1",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb5e41cf91fc4d3187e028f2d9b72970",
            "value": 4540516344
          }
        },
        "26061f499a414f1e90567abd1bd0c673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aadb4671c41f4f548631fabd9865d497",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b80dc258728643f8acfcb77240438893",
            "value": 493443
          }
        },
        "295b99e7a75648bfba95c5d27e3266f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c1350ef56b4547912c22d4698a6c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cbc3d6ec0b941e983b7bbdb47b7f307": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d7d77ee07224c24b8ed9e19fa9b8255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa56380c577245deb4d7b7c594f95e05",
            "placeholder": "​",
            "style": "IPY_MODEL_7258bbe260bb4857ba5840d78b5d9350",
            "value": " 571/571 [00:00&lt;00:00, 56.6kB/s]"
          }
        },
        "2e6d8693ccaf4fe9b2ef4cac428dbeac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0dc14a40634fe6ac07c49d8e56d48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "317659bbb18a42c2901605e125ce47f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7898b52c5c94c2fa26e18d4ff7e9db7",
              "IPY_MODEL_b166de73504f4183878c4080ac6f3279",
              "IPY_MODEL_a9bb432c542c4e38a4770c0e0dbff7cf"
            ],
            "layout": "IPY_MODEL_673fb4e5ceae4d6e8a0542183b9679dc"
          }
        },
        "32bcf6da66e4426fb78606a5ecfb3838": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3525e56f72fe4da385855e01aa5d33e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37e6d7ab044c4cb1aebaf5b111f44fd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df7d4e189c84ad785fe643f059939fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4055bec2770442ab92f06175566205c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4996d3d1fde249a4a3075759559f1ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d990a7f2b1b24955b7cc3d3592663c0a",
              "IPY_MODEL_5e6e7c258b38406abbbdd41b371d8477",
              "IPY_MODEL_d1f559c8bc1a47eaae6d2b36d0593974"
            ],
            "layout": "IPY_MODEL_b59a1c45b10d4c989c419bac3261fa79"
          }
        },
        "4b66776f2ba247aab5a58fe7e07be8c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c46291ff8d54c27ae81a07d48596a11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d009c41613644bf8aef8853c84f6e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d179bfbd7f048cb9ed752911aeb1a93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e229f829da14e27b6cb9373f888c5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e5275fc71484786a25070b7062fa074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a49d0176b040858933a5168071b109",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d009c41613644bf8aef8853c84f6e3d",
            "value": 571
          }
        },
        "4fba1ad00d1d4698aff81e6d4e05cd94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50eac79c7fdd4f8ab8600dc414b379ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5136e93c483d46a8a8373e66d63e69d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53c9bb728c87411a84deceebf06195ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6244d317560b48ea946cb768921aa795",
              "IPY_MODEL_8769c660ac4446e5b51947b21c9b220c",
              "IPY_MODEL_ddbb86469de04a6aac0df809e8ae4876"
            ],
            "layout": "IPY_MODEL_55e8863702a2473faeb5b4db1dc32868"
          }
        },
        "549de8a3c50644bd9f5bb9924f75faf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55d5f7d84c794ff285ac01d816f3571b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0588e535c80e4dbc973110f9306a8cad",
            "placeholder": "​",
            "style": "IPY_MODEL_29c1350ef56b4547912c22d4698a6c6c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "55e8863702a2473faeb5b4db1dc32868": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f3a8ad7d1941f2a2032596d482f522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e80678531d41bcb7aee26176ed72bd",
            "placeholder": "​",
            "style": "IPY_MODEL_0c4c3e1d84624b8cb44b5d778e290d46",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "585d5d7e036742de923dd17ff4063c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58f2594bb2f345ddbf519ba08511bfeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0c51c48d4e44738f6c935e043e1c19",
            "placeholder": "​",
            "style": "IPY_MODEL_b76f840df45943b59bf570e030125abd",
            "value": " 4.54G/4.54G [01:08&lt;00:00, 56.1MB/s]"
          }
        },
        "59b40d98e73141ea9d50adc9fb4002a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d9d97af26bf4cd3b4dd8ee6a6ed5b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc675d54c988490f87cd9c65786660de",
            "placeholder": "​",
            "style": "IPY_MODEL_4055bec2770442ab92f06175566205c7",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "5e6e7c258b38406abbbdd41b371d8477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b40d98e73141ea9d50adc9fb4002a6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f79e9aae4ebf4d019e15209c04d7dfae",
            "value": 2
          }
        },
        "5f4db97186ee4ac7b3b16a4bee6d76ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61006bd517b349608a9b491754759092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce7871e0c6a84951bc446c59fd49f072",
            "placeholder": "​",
            "style": "IPY_MODEL_871dcfdc19414e3ca9be5253368d1b54",
            "value": " 414/414 [00:00&lt;00:00, 28.5kB/s]"
          }
        },
        "6244d317560b48ea946cb768921aa795": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90725aa82e7c4c489f7d6b36ae40e567",
            "placeholder": "​",
            "style": "IPY_MODEL_c2121360c8e34b7fbbc55033312ce8bb",
            "value": "tokenizer.json: 100%"
          }
        },
        "62f87ea27ed84a99b61ffebf32b01ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a710c58f154e058cd38eaa03dd1262": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d9d97af26bf4cd3b4dd8ee6a6ed5b2d",
              "IPY_MODEL_cb274817720443adb9e79ddc1b0801c3",
              "IPY_MODEL_0bc8ca645a3944948156e81b7c99b3ee"
            ],
            "layout": "IPY_MODEL_bb50403432ec420f8b7c7bf227525db8"
          }
        },
        "66707e797f8344bfa910755d521afa0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d179bfbd7f048cb9ed752911aeb1a93",
            "placeholder": "​",
            "style": "IPY_MODEL_00104ad662484e6ca6de32af8133e18b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "673fb4e5ceae4d6e8a0542183b9679dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "676a203d6ddf49f9b49e6676c4c33489": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "704bdf70c444482fb4df26cdf4e688a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fba1ad00d1d4698aff81e6d4e05cd94",
            "placeholder": "​",
            "style": "IPY_MODEL_549de8a3c50644bd9f5bb9924f75faf0",
            "value": " 493k/493k [00:00&lt;00:00, 10.8MB/s]"
          }
        },
        "7258bbe260bb4857ba5840d78b5d9350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7538f544ba494a0ba7d8fdf88c91ff0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da1939a80eb47a38b7939b865a37830": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f53bdec5d3a4163beecd0014604af65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ad57e85c1a408e8cbd96b04ca5c10c",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f4db97186ee4ac7b3b16a4bee6d76ab",
            "value": 25125
          }
        },
        "7f61969b14c6400ea654bb39f6ef0ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85d79d598e7e429498780cf2a6a37220": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37e6d7ab044c4cb1aebaf5b111f44fd0",
            "placeholder": "​",
            "style": "IPY_MODEL_5136e93c483d46a8a8373e66d63e69d2",
            "value": "tokenizer.model: 100%"
          }
        },
        "870faffe7f1548749e1b86d78b99b38f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871dcfdc19414e3ca9be5253368d1b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8769c660ac4446e5b51947b21c9b220c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a619b6ea347841109d033b823544e3e2",
            "max": 1795188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_585d5d7e036742de923dd17ff4063c14",
            "value": 1795188
          }
        },
        "8aa7f73ca5d5449998ed9a2b3eeb4950": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_902ff8f783114369b3bd52840781a385",
            "placeholder": "​",
            "style": "IPY_MODEL_c4e93214e3d54078936241be2995bd41",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "8e4be4a6930b4377ac8e565430fc53d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18720484e3c94eb89356c90beb56f26e",
              "IPY_MODEL_25f5b246f7904d50b9a446aaa95b59ff",
              "IPY_MODEL_58f2594bb2f345ddbf519ba08511bfeb"
            ],
            "layout": "IPY_MODEL_7538f544ba494a0ba7d8fdf88c91ff0f"
          }
        },
        "902ff8f783114369b3bd52840781a385": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90725aa82e7c4c489f7d6b36ae40e567": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b2a4083dcb40ba87e5a53a9bffacf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98a49d0176b040858933a5168071b109": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98db449b0f4a46db91ea83fb32789925": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "994be6fb7e3c4e86ab5d97044ccd488b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a1845f6ff94429783dfe1e06e335faf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a20414ce13a49c99693353ed0b6cb48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf958ae19da4e9cbb4e6b212f11a364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50eac79c7fdd4f8ab8600dc414b379ec",
            "placeholder": "​",
            "style": "IPY_MODEL_32bcf6da66e4426fb78606a5ecfb3838",
            "value": " 25.1k/25.1k [00:00&lt;00:00, 2.07MB/s]"
          }
        },
        "9c25381b12574192a3ee779963261e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e8164defca44950b6ca2fa16da27d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9eb0909db4344547a0099f9f91bdbd32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5491b2f1bd14c63981d88d6a294858b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a619b6ea347841109d033b823544e3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b460bfdae24fe590d54b86bee88d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7da1939a80eb47a38b7939b865a37830",
            "placeholder": "​",
            "style": "IPY_MODEL_ac3b5678d3df40ed857d24d52b2ce763",
            "value": "config.json: 100%"
          }
        },
        "a76499970b984c4daed323153d407cad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9bb432c542c4e38a4770c0e0dbff7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cbc3d6ec0b941e983b7bbdb47b7f307",
            "placeholder": "​",
            "style": "IPY_MODEL_2f0dc14a40634fe6ac07c49d8e56d48a",
            "value": " 2/2 [02:04&lt;00:00, 124.47s/it]"
          }
        },
        "aa56380c577245deb4d7b7c594f95e05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aadb4671c41f4f548631fabd9865d497": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac3b5678d3df40ed857d24d52b2ce763": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad43b2c825a24c149718cf724552150c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b166de73504f4183878c4080ac6f3279": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d2086aebeb243479b1e82aaec992452",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ede4330cc46548f4aef6e3df3be3d84a",
            "value": 2
          }
        },
        "b1a1b987b5a94cb7bb869e020eb7ccfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b59a1c45b10d4c989c419bac3261fa79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76f840df45943b59bf570e030125abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b80dc258728643f8acfcb77240438893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba702c72d3644ca992060c0ac4ab789b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66707e797f8344bfa910755d521afa0c",
              "IPY_MODEL_f33c59a1a2f841eebae801bbbf306cd9",
              "IPY_MODEL_ebf192f26c244593a8eb660dcc66b299"
            ],
            "layout": "IPY_MODEL_3df7d4e189c84ad785fe643f059939fc"
          }
        },
        "bb50403432ec420f8b7c7bf227525db8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbb9cab18d18471c9d8ceba28e576e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a733fbdc8c84248a480c6d578eff6ce",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1a1b987b5a94cb7bb869e020eb7ccfe",
            "value": 414
          }
        },
        "c2121360c8e34b7fbbc55033312ce8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4be1feb785f4f9dbef8a0aeeb335cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57f3a8ad7d1941f2a2032596d482f522",
              "IPY_MODEL_7f53bdec5d3a4163beecd0014604af65",
              "IPY_MODEL_9bf958ae19da4e9cbb4e6b212f11a364"
            ],
            "layout": "IPY_MODEL_1d257a637ed5441a8f5cb98f6a0c7467"
          }
        },
        "c4e93214e3d54078936241be2995bd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb274817720443adb9e79ddc1b0801c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c25381b12574192a3ee779963261e0b",
            "max": 9942981696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3525e56f72fe4da385855e01aa5d33e1",
            "value": 9942981696
          }
        },
        "cc675d54c988490f87cd9c65786660de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce7871e0c6a84951bc446c59fd49f072": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f559c8bc1a47eaae6d2b36d0593974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad43b2c825a24c149718cf724552150c",
            "placeholder": "​",
            "style": "IPY_MODEL_95b2a4083dcb40ba87e5a53a9bffacf4",
            "value": " 2/2 [01:12&lt;00:00, 33.74s/it]"
          }
        },
        "d2ad57e85c1a408e8cbd96b04ca5c10c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58e0aa08ba94f689d3dc23485c4e89e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ccb399b0a74c808e3b9021c0d1ca19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d990a7f2b1b24955b7cc3d3592663c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5491b2f1bd14c63981d88d6a294858b",
            "placeholder": "​",
            "style": "IPY_MODEL_9eb0909db4344547a0099f9f91bdbd32",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ddbb86469de04a6aac0df809e8ae4876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98db449b0f4a46db91ea83fb32789925",
            "placeholder": "​",
            "style": "IPY_MODEL_d5ccb399b0a74c808e3b9021c0d1ca19",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 10.9MB/s]"
          }
        },
        "e298ec3aa95a4b6aa30097077eaf9706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55d5f7d84c794ff285ac01d816f3571b",
              "IPY_MODEL_bbb9cab18d18471c9d8ceba28e576e76",
              "IPY_MODEL_61006bd517b349608a9b491754759092"
            ],
            "layout": "IPY_MODEL_4b66776f2ba247aab5a58fe7e07be8c8"
          }
        },
        "e8e80678531d41bcb7aee26176ed72bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf192f26c244593a8eb660dcc66b299": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2372ff956f2c47e4a67fd80d5235919d",
            "placeholder": "​",
            "style": "IPY_MODEL_994be6fb7e3c4e86ab5d97044ccd488b",
            "value": " 2.10k/2.10k [00:00&lt;00:00, 114kB/s]"
          }
        },
        "ede4330cc46548f4aef6e3df3be3d84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f05fc47f619c499d9095fa4edd3a5e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f33c59a1a2f841eebae801bbbf306cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62f87ea27ed84a99b61ffebf32b01ad4",
            "max": 2103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23917413a3bb4427b5ef7a6379f2f59a",
            "value": 2103
          }
        },
        "f343f93e0e264240a6d3206eaacbfa86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_676a203d6ddf49f9b49e6676c4c33489",
            "placeholder": "​",
            "style": "IPY_MODEL_4e229f829da14e27b6cb9373f888c5cc",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "f7898b52c5c94c2fa26e18d4ff7e9db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e6d8693ccaf4fe9b2ef4cac428dbeac",
            "placeholder": "​",
            "style": "IPY_MODEL_7f61969b14c6400ea654bb39f6ef0ff8",
            "value": "Fetching 2 files: 100%"
          }
        },
        "f79e9aae4ebf4d019e15209c04d7dfae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb5e41cf91fc4d3187e028f2d9b72970": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd083ec6ebf6414b96e6f06ed215e60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85d79d598e7e429498780cf2a6a37220",
              "IPY_MODEL_26061f499a414f1e90567abd1bd0c673",
              "IPY_MODEL_704bdf70c444482fb4df26cdf4e688a4"
            ],
            "layout": "IPY_MODEL_9a1845f6ff94429783dfe1e06e335faf"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
